{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1uAUJGEUzfNj6OsWNAimnYCw7eKaHhMUfU1MTj9YwYw4/edit?usp=sharing), [grading rubric](https://docs.google.com/document/d/1hKuRWqFcIdhOkow3Nljcm7PXzIkoa9c_aHkMKZDxWa0/edit?usp=sharing)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an outline to help you with your own approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import math\n",
    "import os\n",
    "\n",
    "import bs4\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import geopandas as gpd\n",
    "from geopy.distance import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"any constants you might need; some have been added for you, and some you need to fill in\"\"\"\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"data/taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "UBER_CSV = \"\"\n",
    "WEATHER_CSV_DIR = \"\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Make sure the QUERY_DIRECTORY exists\"\"\"\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function takes the shapefile and returns an object\n",
    "    consisting of each zone, locationId and its geomtry coordinates \"\"\"\n",
    "\n",
    "def load_taxi_zones(shapefile):\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "\n",
    "    taxi_zones = []\n",
    "\n",
    "    for index, row in gdf.iterrows():\n",
    "        zone = row.iloc[3]\n",
    "        locationId = row.iloc[4]\n",
    "        geometry = row.iloc[6]\n",
    "        \n",
    "        row_object = { \"zone\": zone, \"locationId\": locationId, \"geometry\": geometry }\n",
    "        taxi_zones.append(row_object)\n",
    "    \n",
    "    return taxi_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "8d04c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function accepts the zone id and the taxi zones\n",
    "    and matches the zone id with its relevant coordinates \"\"\"\n",
    "\n",
    "def lookup_coords_for_taxi_zone_id(zone_loc_id, loaded_taxi_zones):\n",
    "    for i in loaded_taxi_zones:\n",
    "        if i['locationId'] == zone_loc_id:\n",
    "            return i['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ca606b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test - lookup_coords_for_taxi_zone_id() \"\"\"\n",
    "\n",
    "zones = [{ \"zone\": 3, \"locationId\": 1, \"geometry\": 5 }, { \"zone\": 8, \"locationId\": 7, \"geometry\": 3 }]\n",
    "assert lookup_coords_for_taxi_zone_id(1, zones)  == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function calculate the distance giving the pick up\n",
    "    point and drop off point and returns a distance integer \"\"\"\n",
    "\n",
    "def calculate_distance_with_coords(from_coord, to_coord):\n",
    "    pickup_latitude, pickup_longitude = from_coord\n",
    "    dropoff_latitude, dropoff_longitude = to_coord\n",
    "\n",
    "    coords = [pickup_latitude, dropoff_latitude, pickup_longitude, dropoff_longitude]\n",
    "\n",
    "    for i in coords:\n",
    "        if i < -90 or i > 90:\n",
    "            return -1\n",
    "\n",
    "    return distance((pickup_latitude, pickup_longitude), (dropoff_latitude, dropoff_longitude)).miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "d3c5faf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3061822575.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfrom_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m37.7749\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m122.4194\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# San Francisco coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mto_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m34.0522\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m118.2437\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Los Angeles coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_distance_with_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_coord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m347.37\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" test - calculate_distance_with_coords() \"\"\"\n",
    "\n",
    "from_coord = (37.7749, -122.4194)  # San Francisco coordinates\n",
    "to_coord = (34.0522, -118.2437)  # Los Angeles coordinates\n",
    "assert round(calculate_distance_with_coords(from_coord, to_coord), 2) == 347.37\n",
    "\n",
    "\n",
    "from_coord = (105, -122.4194)  # San Francisco coordinates\n",
    "to_coord = (34.0522, -118.2437)  # Los Angeles coordinates\n",
    "assert calculate_distance_with_coords(from_coord, to_coord) == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function adds a new column with the distance between coordinates to the Dataframe.\n",
    "    The input is a dataframe and the output is the new dataframe \"\"\"\n",
    " \n",
    "def add_distance_column(dataframe):\n",
    "    # Apply the calculate_distance_with_coords function to each row of the DataFrame\n",
    "    distances = dataframe.apply(lambda row: calculate_distance_with_coords(\n",
    "        (row[\"pickup_latitude\"], row[\"pickup_longitude\"]),\n",
    "        (row[\"dropoff_latitude\"], row[\"dropoff_longitude\"])\n",
    "    ), axis=1)\n",
    "    \n",
    "    # Add the distances as a new column to the DataFrame\n",
    "    dataframe[\"distance\"] = distances\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "912a73d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' test - add_distance_column() '"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" test - add_distance_column() \"\"\"\n",
    " # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "638e4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function downloads all the relevant files from the taxi webpage\n",
    "    and places it into our local directory \"\"\"\n",
    "\n",
    "def download_files(month, year):\n",
    "    formatted_month = f\"{month:02d}\"\n",
    "    current_dir = os.getcwd()\n",
    "    url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{formatted_month}.parquet\"\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(f\"{current_dir}\\yellow_taxi_{year}_{formatted_month}.parquet\", \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=1024): \n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "years = list(range(2009, 2016))\n",
    "months = list(range(1, 13))\n",
    "\n",
    "for year in years:\n",
    "    if year < 2015:\n",
    "        for month in months:\n",
    "            download_files(month, year)\n",
    "    else:\n",
    "        for month in range(1, 7):\n",
    "            download_files(month, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1d5a3697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FOR MAC\\ndef download_files(month, year):\\n    formatted_month = f\"{month:02d}\"\\n    current_dir = os.getcwd()\\n    url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{formatted_month}.parquet\"\\n\\n    response = requests.get(url, stream=True)\\n    with open(f\"yellow_taxi_{year}_{formatted_month}.parquet\", \"wb\") as f:\\n        for chunk in response.iter_content(chunk_size=1024): \\n            if chunk:\\n                f.write(chunk)\\n\\nyears = list(range(2009, 2016))\\nmonths = list(range(1, 13))\\n\\nfor year in years:\\n    if year < 2015:\\n        for month in months:\\n            download_files(month, year)\\n    else:\\n        for month in range(1, 7):\\n            download_files(month, year)\\n'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"FOR MAC\n",
    "def download_files(month, year):\n",
    "    formatted_month = f\"{month:02d}\"\n",
    "    current_dir = os.getcwd()\n",
    "    url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{formatted_month}.parquet\"\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(f\"yellow_taxi_{year}_{formatted_month}.parquet\", \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=1024): \n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "years = list(range(2009, 2016))\n",
    "months = list(range(1, 13))\n",
    "\n",
    "for year in years:\n",
    "    if year < 2015:\n",
    "        for month in months:\n",
    "            download_files(month, year)\n",
    "    else:\n",
    "        for month in range(1, 7):\n",
    "            download_files(month, year)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "1dd682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function gets all the URLs from the taxi web page and returns\n",
    "    it as an array of strings \"\"\"\n",
    "\n",
    "def get_all_urls_from_taxi_page(taxi_page):\n",
    "    try:\n",
    "        response = requests.get(taxi_page)\n",
    "\n",
    "        soup = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "        urls = []\n",
    "\n",
    "        for link in soup.find_all('a'):\n",
    "            href = link.get('href')\n",
    "            if href is not None:\n",
    "                urls.append(href)\n",
    "\n",
    "        return urls\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "9a7813aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\" test for get_all_urls_from_taxi_page() \"\"\"\n",
    "\n",
    "assert len(get_all_urls_from_taxi_page(TAXI_URL)) == 483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function goes through all the URLs on the taxi web page\n",
    "    and returns only the ones ending in .parquet since we want\n",
    "    parquet files. \"\"\"\n",
    "\n",
    "def filter_taxi_parquet_urls(all_urls):\n",
    "    parquet_urls = []\n",
    "\n",
    "    if all_urls is not None:\n",
    "        for i in all_urls:\n",
    "            str = re.search('.parquet$', i)\n",
    "            if(str != None):\n",
    "                parquet_urls.append(i)\n",
    "    return parquet_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "08f83106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test for filter_taxi_parquet_urls() \"\"\"\n",
    "\n",
    "allUrlsData = get_all_urls_from_taxi_page(TAXI_URL)\n",
    "assert len(filter_taxi_parquet_urls(allUrlsData)) == 428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function takes a URL and extracts the month from it\n",
    "    The example url can look like:\n",
    "    https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet \"\"\"\n",
    "\n",
    "def get_and_clean_month(url):\n",
    "    str = url[len(url) - 10:]\n",
    "    [month, fileType] = str.split('.')\n",
    "    return month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "15238bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test for get_and_clean_month function \"\"\"\n",
    "\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet'\n",
    "assert get_and_clean_month(url) == '06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "f15da82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function takes a URL and extracts the year from it\n",
    "    The example url can look like:\n",
    "    https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet \"\"\"\n",
    "\n",
    "def get_and_clean_year(url):\n",
    "    str = url[len(url) - 15:]\n",
    "    [year, other] = str.split('-')\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "9aee9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test for get_and_clean_year function \"\"\"\n",
    "\n",
    "url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet'\n",
    "assert get_and_clean_year(url) == '2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "cd58b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This fucntion adds a new column with the distance between coordinates to the taxi Dataframe.\n",
    "    The input is a dataframe and the output is the new modified dataframe \"\"\"\n",
    " \n",
    "def add_distance_column_taxi(dataframe):\n",
    "    # Apply the calculate_distance_with_coords function to each row of the DataFrame\n",
    "    distances = dataframe.apply(lambda row: calculate_distance_with_coords(\n",
    "        (row[\"Start_Lat\"], row[\"Start_Lon\"]),\n",
    "        (row[\"End_Lat\"], row[\"End_Lon\"])\n",
    "    ), axis=1)\n",
    "    \n",
    "    # Add the distances as a new column to the DataFrame\n",
    "    dataframe[\"distance\"] = distances\n",
    "    \n",
    "    return dataframe[\"distance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function collects all the parquet urls from the taxi website.\n",
    "    It will then get the actual data from the parquet files and do various forms of cleaning.\n",
    "    For example, we will remove unnecessary columns and invalid data and will return\n",
    "    one gigantic dataframe with data from every month \"\"\"\n",
    "\n",
    "def convert_taxi_data(parquet_urls):\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    for parquet_url in parquet_urls:\n",
    "        month = get_and_clean_month(parquet_url)\n",
    "        year = get_and_clean_year(parquet_url)\n",
    "\n",
    "        cwd = os.getcwd()\n",
    "        files = os.listdir(cwd)\n",
    "\n",
    "        fileName = f\"yellow_taxi_{year}_{month}.parquet\"\n",
    "        if fileName in files :\n",
    "\n",
    "            dataframe = pd.read_parquet(fileName)\n",
    "            sample_dataframe = dataframe.sample(n=2000)\n",
    "            #add_distance_column_taxi(sample_dataframe)\n",
    "            all_taxi_dataframes.append(sample_dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "\n",
    "    print(len(taxi_data))\n",
    "    print(len(taxi_data.head()))\n",
    "\n",
    "    return taxi_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "8fa08c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267500\n"
     ]
    }
   ],
   "source": [
    "all_urls = get_all_urls_from_taxi_page(TAXI_URL)\n",
    "all_parquet_urls = filter_taxi_parquet_urls(all_urls)\n",
    "taxi_data = convert_taxi_data(all_parquet_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "200776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function gets all the urls from the taxi page, specifically the parquet urls,\n",
    "    gets and cleans it, and returns the valid data \"\"\"\n",
    "\n",
    "def get_taxi_data():\n",
    "    all_urls = get_all_urls_from_taxi_page(TAXI_URL)\n",
    "    all_parquet_urls = filter_taxi_parquet_urls(all_urls)\n",
    "    taxi_data = convert_taxi_data(all_parquet_urls)\n",
    "\n",
    "    return taxi_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ac161e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>...</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Rate_Code</th>\n",
       "      <th>store_and_forward</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>Payment_Type</th>\n",
       "      <th>Fare_Amt</th>\n",
       "      <th>Tip_Amt</th>\n",
       "      <th>Tolls_Amt</th>\n",
       "      <th>Total_Amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>811716</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-01-03 08:34:22</td>\n",
       "      <td>2015-01-03 08:40:27</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>142.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928642</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-06 10:42:38</td>\n",
       "      <td>2015-01-06 11:08:03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>236.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10980337</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-01-28 08:23:39</td>\n",
       "      <td>2015-01-28 08:32:12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.44</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>231.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3580296</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-01-10 01:52:05</td>\n",
       "      <td>2015-01-10 01:55:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>48.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1545519</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-01-05 09:29:16</td>\n",
       "      <td>2015-01-05 09:50:43</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>238.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
       "811716         2.0  2015-01-03 08:34:22   2015-01-03 08:40:27   \n",
       "1928642        1.0  2015-01-06 10:42:38   2015-01-06 11:08:03   \n",
       "10980337       2.0  2015-01-28 08:23:39   2015-01-28 08:32:12   \n",
       "3580296        1.0  2015-01-10 01:52:05   2015-01-10 01:55:19   \n",
       "1545519        2.0  2015-01-05 09:29:16   2015-01-05 09:50:43   \n",
       "\n",
       "          passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
       "811716                5.0           1.80         1.0                  N   \n",
       "1928642               1.0           1.30         1.0                  N   \n",
       "10980337              1.0           1.44         1.0                  N   \n",
       "3580296               1.0           0.80         1.0                  N   \n",
       "1545519               1.0           3.30         1.0                  N   \n",
       "\n",
       "          PULocationID  DOLocationID payment_type  ...  Start_Lat  Rate_Code  \\\n",
       "811716           142.0          43.0            1  ...        NaN        NaN   \n",
       "1928642          236.0          75.0            2  ...        NaN        NaN   \n",
       "10980337         231.0         249.0            1  ...        NaN        NaN   \n",
       "3580296           48.0          48.0            1  ...        NaN        NaN   \n",
       "1545519          238.0         186.0            2  ...        NaN        NaN   \n",
       "\n",
       "          store_and_forward  End_Lon  End_Lat  Payment_Type  Fare_Amt Tip_Amt  \\\n",
       "811716                  NaN      NaN      NaN           NaN       NaN     NaN   \n",
       "1928642                 NaN      NaN      NaN           NaN       NaN     NaN   \n",
       "10980337                NaN      NaN      NaN           NaN       NaN     NaN   \n",
       "3580296                 NaN      NaN      NaN           NaN       NaN     NaN   \n",
       "1545519                 NaN      NaN      NaN           NaN       NaN     NaN   \n",
       "\n",
       "         Tolls_Amt Total_Amt  \n",
       "811716         NaN       NaN  \n",
       "1928642        NaN       NaN  \n",
       "10980337       NaN       NaN  \n",
       "3580296        NaN       NaN  \n",
       "1545519        NaN       NaN  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function first loads the uber data from the csv file. \n",
    "We then filter based on coordinates to make sure the rides are within the coordinates we want.\n",
    "We also remove trips with 0 passangers and no fares. We further remove trips with passangers above 6 as that \n",
    "is uber policy. Lastly we remove trips with no distace between dropoff and pickup. The output is the\n",
    "cleaned dataframe\"\"\"\n",
    "\n",
    "def load_and_clean_uber_data(csv_file):\n",
    "\n",
    "    # Reading in file into a data frame \n",
    "    uber_data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Filter data based on pickup and dropoff latitude/longitude(40.560445, -74.242330) and (40.908524, -73.717047).\n",
    "\n",
    "    uber_data = uber_data[(uber_data[\"pickup_latitude\"] >= 40.560445) & \n",
    "                      (uber_data[\"pickup_longitude\"] >= -74.242330) & \n",
    "                      (uber_data[\"pickup_latitude\"] <= 40.908524) & \n",
    "                      (uber_data[\"pickup_longitude\"] <= -73.717047) &\n",
    "                      (uber_data[\"dropoff_latitude\"] >= 40.560445) & \n",
    "                      (uber_data[\"dropoff_longitude\"] >= -74.242330) & \n",
    "                      (uber_data[\"dropoff_latitude\"] <= 40.908524) & \n",
    "                      (uber_data[\"dropoff_longitude\"] <= -73.717047)]\n",
    "    \n",
    "    # Checking if there are any null values for pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude\n",
    "    null_drop_lat = uber_data[uber_data['dropoff_latitude'].isnull()]\n",
    "    null_drop_long = uber_data[uber_data['dropoff_longitude'].isnull()]\n",
    "    null_pick_lat= uber_data[uber_data['pickup_latitude'].isnull()]\n",
    "    null_pick_long = uber_data[uber_data['pickup_longitude'].isnull()]\n",
    "\n",
    "    # Return True, if none of the colums have null values \n",
    "\n",
    "   # if null_drop_lat.empty & null_drop_long.empty & null_pick_lat.empty & null_pick_long.empty :\n",
    "        #print(True)\n",
    "    #else:\n",
    "       # print(False)\n",
    "\n",
    "    \n",
    "    # Removing rows where passamger count is 0 \n",
    "    uber_data = uber_data[uber_data['passenger_count']!=0]\n",
    "\n",
    "\n",
    "    # Removing rows with passanger data is abnormally large \n",
    "    uber_data = uber_data[uber_data['passenger_count']<=6]\n",
    "\n",
    "    # Checking datatypes for all columns \n",
    "    #print(uber_data.dtypes)\n",
    "\n",
    "    #Making sure pickup time is a datetime object and normalizing the name \n",
    "    uber_data ['pickup_time'] = pd.to_datetime(uber_data ['pickup_datetime'])\n",
    " \n",
    "\n",
    "\n",
    "    return uber_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" We use the add distance column fcuntion we had defined before to add a new column with the distance \n",
    "of the ride to our uber data. We also drop columns where the distance of the ride is ==0\"\"\"\n",
    "\n",
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(\"uber_rides_sample.csv\")\n",
    "    add_distance_column(uber_dataframe)\n",
    "    \n",
    "    # Removing rows where distance is 0\n",
    "\n",
    "    uber_dataframe = uber_dataframe.drop(index=uber_dataframe[uber_dataframe['distance'] == 0].index)\n",
    "    return uber_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9c2bd13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24238194</td>\n",
       "      <td>2015-05-07 19:52:06.0000003</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>1.044594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27835199</td>\n",
       "      <td>2009-07-17 20:04:56.0000002</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>1.525071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44984355</td>\n",
       "      <td>2009-08-24 21:45:00.00000061</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>3.131464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25894730</td>\n",
       "      <td>2009-06-26 08:22:21.0000001</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>1.032372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17610152</td>\n",
       "      <td>2014-08-28 17:47:00.000000188</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>2.786061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>42598914</td>\n",
       "      <td>2012-10-28 10:49:00.00000053</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-10-28 10:49:00 UTC</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "      <td>0.069673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>16382965</td>\n",
       "      <td>2014-03-14 01:09:00.0000008</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-03-14 01:09:00 UTC</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "      <td>1.167951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>27804658</td>\n",
       "      <td>2009-06-29 00:42:00.00000078</td>\n",
       "      <td>30.9</td>\n",
       "      <td>2009-06-29 00:42:00 UTC</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "      <td>7.995752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>20259894</td>\n",
       "      <td>2015-05-20 14:56:25.0000004</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2015-05-20 14:56:25 UTC</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "      <td>2.197512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>11951496</td>\n",
       "      <td>2010-05-15 04:08:00.00000076</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2010-05-15 04:08:00 UTC</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "      <td>3.362040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192829 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                            key  fare_amount  \\\n",
       "0         24238194    2015-05-07 19:52:06.0000003          7.5   \n",
       "1         27835199    2009-07-17 20:04:56.0000002          7.7   \n",
       "2         44984355   2009-08-24 21:45:00.00000061         12.9   \n",
       "3         25894730    2009-06-26 08:22:21.0000001          5.3   \n",
       "4         17610152  2014-08-28 17:47:00.000000188         16.0   \n",
       "...            ...                            ...          ...   \n",
       "199995    42598914   2012-10-28 10:49:00.00000053          3.0   \n",
       "199996    16382965    2014-03-14 01:09:00.0000008          7.5   \n",
       "199997    27804658   2009-06-29 00:42:00.00000078         30.9   \n",
       "199998    20259894    2015-05-20 14:56:25.0000004         14.5   \n",
       "199999    11951496   2010-05-15 04:08:00.00000076         14.1   \n",
       "\n",
       "                pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0       2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
       "1       2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
       "2       2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
       "3       2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
       "4       2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
       "...                         ...               ...              ...   \n",
       "199995  2012-10-28 10:49:00 UTC        -73.987042        40.739367   \n",
       "199996  2014-03-14 01:09:00 UTC        -73.984722        40.736837   \n",
       "199997  2009-06-29 00:42:00 UTC        -73.986017        40.756487   \n",
       "199998  2015-05-20 14:56:25 UTC        -73.997124        40.725452   \n",
       "199999  2010-05-15 04:08:00 UTC        -73.984395        40.720077   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0              -73.999512         40.723217                1   \n",
       "1              -73.994710         40.750325                1   \n",
       "2              -73.962565         40.772647                1   \n",
       "3              -73.965316         40.803349                3   \n",
       "4              -73.973082         40.761247                5   \n",
       "...                   ...               ...              ...   \n",
       "199995         -73.986525         40.740297                1   \n",
       "199996         -74.006672         40.739620                1   \n",
       "199997         -73.858957         40.692588                2   \n",
       "199998         -73.983215         40.695415                1   \n",
       "199999         -73.985508         40.768793                1   \n",
       "\n",
       "                     pickup_time  distance  \n",
       "0      2015-05-07 19:52:06+00:00  1.044594  \n",
       "1      2009-07-17 20:04:56+00:00  1.525071  \n",
       "2      2009-08-24 21:45:00+00:00  3.131464  \n",
       "3      2009-06-26 08:22:21+00:00  1.032372  \n",
       "4      2014-08-28 17:47:00+00:00  2.786061  \n",
       "...                          ...       ...  \n",
       "199995 2012-10-28 10:49:00+00:00  0.069673  \n",
       "199996 2014-03-14 01:09:00+00:00  1.167951  \n",
       "199997 2009-06-29 00:42:00+00:00  7.995752  \n",
       "199998 2015-05-20 14:56:25+00:00  2.197512  \n",
       "199999 2010-05-15 04:08:00+00:00  3.362040  \n",
       "\n",
       "[192829 rows x 11 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_uber_data = get_uber_data()\n",
    "final_uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "826a4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unnecessary columns \n",
    "final_uber_data = final_uber_data.drop('Unnamed: 0', axis=1)\n",
    "final_uber_data = final_uber_data.drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "339997e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>1.044594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>1.525071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>3.131464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>1.032372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>2.786061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-10-28 10:49:00 UTC</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "      <td>0.069673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-03-14 01:09:00 UTC</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "      <td>1.167951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>30.9</td>\n",
       "      <td>2009-06-29 00:42:00 UTC</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "      <td>7.995752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>14.5</td>\n",
       "      <td>2015-05-20 14:56:25 UTC</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "      <td>2.197512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>14.1</td>\n",
       "      <td>2010-05-15 04:08:00 UTC</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "      <td>3.362040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192829 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount          pickup_datetime  pickup_longitude  \\\n",
       "0               7.5  2015-05-07 19:52:06 UTC        -73.999817   \n",
       "1               7.7  2009-07-17 20:04:56 UTC        -73.994355   \n",
       "2              12.9  2009-08-24 21:45:00 UTC        -74.005043   \n",
       "3               5.3  2009-06-26 08:22:21 UTC        -73.976124   \n",
       "4              16.0  2014-08-28 17:47:00 UTC        -73.925023   \n",
       "...             ...                      ...               ...   \n",
       "199995          3.0  2012-10-28 10:49:00 UTC        -73.987042   \n",
       "199996          7.5  2014-03-14 01:09:00 UTC        -73.984722   \n",
       "199997         30.9  2009-06-29 00:42:00 UTC        -73.986017   \n",
       "199998         14.5  2015-05-20 14:56:25 UTC        -73.997124   \n",
       "199999         14.1  2010-05-15 04:08:00 UTC        -73.984395   \n",
       "\n",
       "        pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0             40.738354         -73.999512         40.723217                1   \n",
       "1             40.728225         -73.994710         40.750325                1   \n",
       "2             40.740770         -73.962565         40.772647                1   \n",
       "3             40.790844         -73.965316         40.803349                3   \n",
       "4             40.744085         -73.973082         40.761247                5   \n",
       "...                 ...                ...               ...              ...   \n",
       "199995        40.739367         -73.986525         40.740297                1   \n",
       "199996        40.736837         -74.006672         40.739620                1   \n",
       "199997        40.756487         -73.858957         40.692588                2   \n",
       "199998        40.725452         -73.983215         40.695415                1   \n",
       "199999        40.720077         -73.985508         40.768793                1   \n",
       "\n",
       "                     pickup_time  distance  \n",
       "0      2015-05-07 19:52:06+00:00  1.044594  \n",
       "1      2009-07-17 20:04:56+00:00  1.525071  \n",
       "2      2009-08-24 21:45:00+00:00  3.131464  \n",
       "3      2009-06-26 08:22:21+00:00  1.032372  \n",
       "4      2014-08-28 17:47:00+00:00  2.786061  \n",
       "...                          ...       ...  \n",
       "199995 2012-10-28 10:49:00+00:00  0.069673  \n",
       "199996 2014-03-14 01:09:00+00:00  1.167951  \n",
       "199997 2009-06-29 00:42:00+00:00  7.995752  \n",
       "199998 2015-05-20 14:56:25+00:00  2.197512  \n",
       "199999 2010-05-15 04:08:00+00:00  3.362040  \n",
       "\n",
       "[192829 rows x 9 columns]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_uber_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function takes all the weather files, iterates through them and merges them \n",
    "into one dataframe. The output is the combined dataframe\"\"\"\n",
    "\n",
    "def get_all_weather_csvs():\n",
    "    years = list(range(2009, 2016))\n",
    "\n",
    "    # Initialize an empty list to store the dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    # Iterate over the weather files\n",
    "    for year in years:\n",
    "        filepath = f\"{year}_weather.csv\"\n",
    "        df = pd.read_csv(filepath)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Concatenate all the dataframes into a single dataframe\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fb7e80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function first loads the uber data from the csv file. \n",
    "We then filter based on coordinates to make sure the rides are within the coordinates we want.\n",
    "We also remove trips with 0 passangers and no fares. We further remove trips with passangers above 6 as that \n",
    "is uber policy. Lastly we remove trips with no distace between dropoff and pickup. The output is the\n",
    "cleaned dataframe\"\"\"\n",
    "\n",
    "def load_and_clean_weather_data():\n",
    "\n",
    "    df = get_all_weather_csvs()\n",
    "\n",
    "    df1 = df[['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'NAME','HourlyPrecipitation','HourlyWindGustSpeed', 'HourlyWindSpeed', 'DailyAverageWindSpeed','DailyPrecipitation']]\n",
    "    df2 = df1.dropna(subset=['HourlyPrecipitation', 'HourlyWindGustSpeed'])\n",
    "\n",
    "    #column_types = df2.dtypes\n",
    "\n",
    "    #print(column_types)\n",
    "\n",
    "    # we see that the averages for wind speed and precipitation are null for all values so we can drop the columns \n",
    "\n",
    "    # We also doing need the hourly wind gust speed as we will be using the hourly wind speed, we can drop that column as well\n",
    "\n",
    "    df2 = df2.drop(columns=['DailyAverageWindSpeed','DailyPrecipitation', 'HourlyWindGustSpeed','LATITUDE', 'LONGITUDE'])\n",
    "    df2['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "    df2\n",
    "\n",
    "    # Removing all rows where Hourly preicipitation has the value \"T\" as we do not need to measure trace amounts \n",
    "\n",
    "    df3 = df2[df2['HourlyPrecipitation'] != \"T\"]\n",
    "\n",
    "    df4 = df3.drop(columns=[\"STATION\"])\n",
    "\n",
    "    df4 = df4.reset_index()\n",
    "\n",
    "    df4['DATE'] = df4['DATE'].apply(lambda x: x.to_pydatetime())\n",
    "\n",
    "    df4['DATE'] = pd.to_datetime(df4['DATE'])\n",
    "\n",
    "    df4['HourlyPrecipitation'] = df4['HourlyPrecipitation'].str.replace(r'(\\d+)\\s*[sS]$', r'\\1', regex=True)\n",
    "    \n",
    "    # convert column \"A\" from object to float\n",
    "    df4['HourlyPrecipitation'] = df4['HourlyPrecipitation'].astype(float)\n",
    "\n",
    "    Weather_Data = df4.drop('index', axis=1)\n",
    "\n",
    "    return  Weather_Data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "7a3a9156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-06 20:00:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-06 23:38:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-07 02:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-07 03:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.06</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-07 04:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.07</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>2015-12-29 10:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>2015-12-29 11:33:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>2015-12-29 11:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>2015-12-31 11:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>2015-12-31 20:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7103 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DATE                         NAME  HourlyPrecipitation  \\\n",
       "0    2009-01-06 20:00:00  NY CITY CENTRAL PARK, NY US                 0.01   \n",
       "1    2009-01-06 23:38:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "2    2009-01-07 02:51:00  NY CITY CENTRAL PARK, NY US                 0.09   \n",
       "3    2009-01-07 03:51:00  NY CITY CENTRAL PARK, NY US                 0.06   \n",
       "4    2009-01-07 04:51:00  NY CITY CENTRAL PARK, NY US                 0.07   \n",
       "...                  ...                          ...                  ...   \n",
       "7098 2015-12-29 10:51:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "7099 2015-12-29 11:33:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "7100 2015-12-29 11:51:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "7101 2015-12-31 11:51:00  NY CITY CENTRAL PARK, NY US                 0.00   \n",
       "7102 2015-12-31 20:51:00  NY CITY CENTRAL PARK, NY US                 0.00   \n",
       "\n",
       "      HourlyWindSpeed  \n",
       "0                10.0  \n",
       "1                11.0  \n",
       "2                13.0  \n",
       "3                15.0  \n",
       "4                16.0  \n",
       "...               ...  \n",
       "7098             10.0  \n",
       "7099              8.0  \n",
       "7100              6.0  \n",
       "7101              9.0  \n",
       "7102             10.0  \n",
       "\n",
       "[7103 rows x 4 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Roll up the data to daily\"\"\"\n",
    "def clean_month_weather_data_daily():\n",
    "\n",
    "    daily_data = load_and_clean_weather_data()\n",
    "\n",
    "    daily_data_final = daily_data.groupby([daily_data['DATE'].dt.year, daily_data['DATE'].dt.month, daily_data['DATE'].dt.day]).sum()[['HourlyPrecipitation', \"HourlyWindSpeed\" ]]\n",
    "\n",
    "    daily_data_final = daily_data_final.rename_axis(index=['Year', 'Month', 'Day'])\n",
    "\n",
    "\n",
    "    \n",
    "    return daily_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "e3e6f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly():\n",
    "\n",
    "    hourly_data = load_and_clean_weather_data()\n",
    "\n",
    "    hourly_data_final = hourly_data.groupby([hourly_data['DATE'].dt.year, hourly_data['DATE'].dt.month, hourly_data['DATE'].dt.day, hourly_data['DATE'].dt.hour]).sum()[['HourlyPrecipitation', \"HourlyWindSpeed\" ]]\n",
    "\n",
    "    hourly_data_final = hourly_data_final.rename_axis(index=['Year', 'Month', 'Day', 'Hour'])\n",
    "    \n",
    "    return hourly_data_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3ef8945d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef load_and_clean_weather_data():\\n    weather_csv_files = get_all_weather_csvs()\\n    \\n    hourly_dataframes = []\\n    daily_dataframes = []\\n        \\n    for csv_file in weather_csv_files:\\n        hourly_dataframe = clean_month_weather_data_hourly()\\n        daily_dataframe = clean_month_weather_data_daily()\\n        hourly_dataframes.append(hourly_dataframe)\\n        daily_dataframes.append(daily_dataframe)\\n        \\n    # create two dataframes with hourly & daily data from every month\\n    hourly_data = pd.concat(hourly_dataframes)\\n    daily_data = pd.concat(daily_dataframes)\\n    \\n    return hourly_data, daily_data\\n    '"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" I dont think this is needed as my daily and hourly functions retunr the datframes that we need\"\"\"\n",
    "\"\"\"\n",
    "def load_and_clean_weather_data():\n",
    "    weather_csv_files = get_all_weather_csvs()\n",
    "    \n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "        \n",
    "    for csv_file in weather_csv_files:\n",
    "        hourly_dataframe = clean_month_weather_data_hourly()\n",
    "        daily_dataframe = clean_month_weather_data_daily()\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "48216557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2009</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>20</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.02</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">7</th>\n",
       "      <th>2</th>\n",
       "      <td>0.09</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.07</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     HourlyPrecipitation  HourlyWindSpeed\n",
       "Year Month Day Hour                                      \n",
       "2009 1     6   20                   0.01             10.0\n",
       "               23                   0.02             11.0\n",
       "           7   2                    0.09             13.0\n",
       "               3                    0.06             15.0\n",
       "               4                    0.07             16.0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data = clean_month_weather_data_hourly()\n",
    "hourly_weather_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fe40d91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.07</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5809</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>0.07</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5810</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5811</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>0.04</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5812</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5813</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5814 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Month  Day  Hour  HourlyPrecipitation  HourlyWindSpeed\n",
       "0     2009      1    6    20                 0.01             10.0\n",
       "1     2009      1    6    23                 0.02             11.0\n",
       "2     2009      1    7     2                 0.09             13.0\n",
       "3     2009      1    7     3                 0.06             15.0\n",
       "4     2009      1    7     4                 0.07             16.0\n",
       "...    ...    ...  ...   ...                  ...              ...\n",
       "5809  2015     12   29     9                 0.07             19.0\n",
       "5810  2015     12   29    10                 0.13             29.0\n",
       "5811  2015     12   29    11                 0.04             14.0\n",
       "5812  2015     12   31    11                 0.00              9.0\n",
       "5813  2015     12   31    20                 0.00             10.0\n",
       "\n",
       "[5814 rows x 6 columns]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hourly_weather_data = hourly_weather_data.reset_index()\n",
    "hourly_weather_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4cb386ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3776051388.py:13: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.13</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.26</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.69</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.75</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Month  Day  HourlyPrecipitation  HourlyWindSpeed\n",
       "0     2009      1    6                 0.03             21.0\n",
       "1     2009      1    7                 1.13            224.0\n",
       "2     2009      1   10                 0.06             48.0\n",
       "3     2009      1   11                 0.26             67.0\n",
       "4     2009      1   17                 0.69              7.0\n",
       "...    ...    ...  ...                  ...              ...\n",
       "1026  2015     12   26                 0.00             76.0\n",
       "1027  2015     12   27                 0.02             58.0\n",
       "1028  2015     12   28                 0.00             70.0\n",
       "1029  2015     12   29                 0.75            167.0\n",
       "1030  2015     12   31                 0.00             19.0\n",
       "\n",
       "[1031 rows x 5 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data = clean_month_weather_data_daily()\n",
    "daily_weather_data = daily_weather_data.reset_index()\n",
    "\n",
    "daily_weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "    CREATE TABLE HOURLY_WEATHER (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        year INTEGER,\n",
    "        month INTEGER,\n",
    "        day INTEGER,\n",
    "        hour INTEGER,\n",
    "        precipitation REAL,\n",
    "        wind REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "    CREATE TABLE DAILY_WEATHER (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        year INTEGER,\n",
    "        month INTEGER,\n",
    "        day INTEGER,\n",
    "        precipitation REAL,\n",
    "        wind REAL\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS TAXI_TRIPS (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        pickup_datetime TEXT,\n",
    "        pickup_longitude REAL,\n",
    "        pickup_latitude REAL,\n",
    "        dropoff_longitude REAL,\n",
    "        dropoff_latitude REAL,\n",
    "        fare_amount REAL,\n",
    "        distance REAL,\n",
    "        passenger_count INTEGER,\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS UBER_TRIPS (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        pickup_datetime TEXT,\n",
    "        pickup_longitude REAL,\n",
    "        pickup_latitude REAL,\n",
    "        dropoff_longitude REAL,\n",
    "        dropoff_latitude REAL,\n",
    "        fare_amount REAL,\n",
    "        distance REAL,\n",
    "        passenger_count INTEGER,\n",
    "    );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table():\n",
    "\n",
    "    hourly_weather_data.to_sql(name='HOURLY_WEATHER', con=engine, if_exists='replace', index=False)\n",
    "    daily_weather_data.to_sql(name='DAILY_WEATHER', con=engine, if_exists='replace', index=False)\n",
    "    final_uber_data.to_sql(name='UBER_TRIPS', con=engine, if_exists='replace', index=False)\n",
    "    #.to_sql(name='UBER_TRIPS', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "    \n",
    "write_dataframes_to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8e495251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7.5, '2015-05-07 19:52:06 UTC', -73.99981689453125, 40.73835372924805, -73.99951171875, 40.72321701049805, 1, '2015-05-07 19:52:06.000000', 1.0445937861491572)\n",
      "(7.7, '2009-07-17 20:04:56 UTC', -73.994355, 40.728225, -73.99471, 40.750325, 1, '2009-07-17 20:04:56.000000', 1.5250706123331683)\n",
      "(12.9, '2009-08-24 21:45:00 UTC', -74.005043, 40.74077, -73.962565, 40.772647, 1, '2009-08-24 21:45:00.000000', 3.1314639281870544)\n",
      "(5.3, '2009-06-26 08:22:21 UTC', -73.976124, 40.790844, -73.965316, 40.803349, 3, '2009-06-26 08:22:21.000000', 1.0323719006396994)\n",
      "(16.0, '2014-08-28 17:47:00 UTC', -73.925023, 40.744085, -73.97308199999999, 40.761247, 5, '2014-08-28 17:47:00.000000', 2.7860607099399095)\n",
      "(24.5, '2014-10-12 07:04:00 UTC', -73.96144699999999, 40.693965000000006, -73.871195, 40.774297, 5, '2014-10-12 07:04:00.000000', 7.291584115691231)\n",
      "(9.7, '2012-02-17 09:32:00 UTC', -73.975187, 40.745767, -74.00272, 40.743537, 1, '2012-02-17 09:32:00.000000', 1.4531136025314275)\n",
      "(12.5, '2012-03-29 19:06:00 UTC', -74.001065, 40.741787, -73.96304, 40.775012, 1, '2012-03-29 19:06:00.000000', 3.03920190901205)\n",
      "(6.5, '2015-05-22 17:32:27 UTC', -73.9743881225586, 40.74695205688477, -73.98858642578125, 40.729804992675774, 1, '2015-05-22 17:32:27.000000', 1.3983093536526319)\n",
      "(3.3, '2011-05-17 14:03:00 UTC', -73.966378, 40.80444, -73.96589, 40.807133, 5, '2011-05-17 14:03:00.000000', 0.18757937383887208)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "query = \"SELECT * FROM UBER_TRIPS LIMIT 10;\"\n",
    "result = engine.execute(query)\n",
    "\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1_FILENAME = \"\"\n",
    "\n",
    "QUERY_1 = \"\"\"\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_1(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "plot_visual_1(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c350a277",
   "metadata": {},
   "source": [
    "### Visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02eeb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_2(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_2():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_2()\n",
    "plot_visual_2(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "275a1af2",
   "metadata": {},
   "source": [
    "### Visualization 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e60fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_3(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_3():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_3()\n",
    "plot_visual_3(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e085f33",
   "metadata": {},
   "source": [
    "### Visualization 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_4(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_4():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_4()\n",
    "plot_visual_4(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9029b60",
   "metadata": {},
   "source": [
    "### Visualization 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdcd1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_5(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_5():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_5()\n",
    "plot_visual_5(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "410cfcdd",
   "metadata": {},
   "source": [
    "### Visualization 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fa4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a more descriptive name for your function\n",
    "def plot_visual_6(dataframe):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    values = \"...\"  # use the dataframe to pull out values needed to plot\n",
    "    \n",
    "    # you may want to use matplotlib to plot your visualizations;\n",
    "    # there are also many other plot types (other \n",
    "    # than axes.plot) you can use\n",
    "    axes.plot(values, \"...\")\n",
    "    # there are other methods to use to label your axes, to style \n",
    "    # and set up axes labels, etc\n",
    "    axes.set_title(\"Some Descriptive Title\")\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_6():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_6()\n",
    "plot_visual_6(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d659ea492a6423f437f8c825d2ef59ba06a7f23250fb4bfa35b0a006bd446c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
