{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1uAUJGEUzfNj6OsWNAimnYCw7eKaHhMUfU1MTj9YwYw4/edit?usp=sharing), [grading rubric](https://docs.google.com/document/d/1hKuRWqFcIdhOkow3Nljcm7PXzIkoa9c_aHkMKZDxWa0/edit?usp=sharing)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an outline to help you with your own approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "import math\n",
    "import os\n",
    "import bs4\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import requests\n",
    "import itertools\n",
    "import sqlalchemy as db\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from geopy.distance import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"any constants you might need; some have been added for you, and some you need to fill in\"\"\"\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"data/taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "UBER_CSV = \"\"\n",
    "WEATHER_CSV_DIR = \"\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Make sure the QUERY_DIRECTORY exists\"\"\"\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function takes the shapefile and returns an object\n",
    "    consisting of each zone, locationId and its geomtry coordinates \"\"\"\n",
    "\n",
    "def load_taxi_zones(shapefile: str) -> dict:\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "\n",
    "    taxi_zones = []\n",
    "\n",
    "    for index, row in gdf.iterrows():\n",
    "        zone = row.iloc[3]\n",
    "        locationId = row.iloc[4]\n",
    "        geometry = row.iloc[6]\n",
    "        \n",
    "        row_object = { \"zone\": zone, \"locationId\": locationId, \"geometry\": geometry }\n",
    "        taxi_zones.append(row_object)\n",
    "    \n",
    "    return taxi_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "8d04c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function accepts the zone id and the taxi zones\n",
    "    and matches the zone id with its relevant coordinates \"\"\"\n",
    "\n",
    "def lookup_coords_for_taxi_zone_id(zone_loc_id: int, loaded_taxi_zones: list) -> int:\n",
    "    for i in loaded_taxi_zones:\n",
    "        if i['locationId'] == zone_loc_id:\n",
    "            return i['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "ca606b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test - lookup_coords_for_taxi_zone_id() \"\"\"\n",
    "\n",
    "def lookup_coords_for_taxi_zone_id_test():\n",
    "\n",
    "    zones = [{ \"zone\": 3, \"locationId\": 1, \"geometry\": 5 }, { \"zone\": 8, \"locationId\": 7, \"geometry\": 3 }]\n",
    "    assert lookup_coords_for_taxi_zone_id(1, zones)  == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function calculate the distance giving the pick up\n",
    "    point and drop off point and returns a distance integer \"\"\"\n",
    "\n",
    "def calculate_distance_with_coords(from_coord: tuple, to_coord: tuple) -> int:\n",
    "    pickup_latitude, pickup_longitude = from_coord\n",
    "    dropoff_latitude, dropoff_longitude = to_coord\n",
    "\n",
    "    coords = [pickup_latitude, dropoff_latitude, pickup_longitude, dropoff_longitude]\n",
    "\n",
    "    for i in coords:\n",
    "        if i < -90 or i > 90:\n",
    "            return -1\n",
    "\n",
    "    return distance((pickup_latitude, pickup_longitude), (dropoff_latitude, dropoff_longitude)).miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "d3c5faf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/3061822575.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfrom_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m37.7749\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m122.4194\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# San Francisco coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mto_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m34.0522\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m118.2437\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Los Angeles coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculate_distance_with_coords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_coord\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_coord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m347.37\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\" test - calculate_distance_with_coords() \"\"\"\n",
    "\n",
    "def calculate_distance_with_coords_test():\n",
    "\n",
    "    from_coord = (37.7749, -12.4194)\n",
    "    to_coord = (34.0522, -11.2437)\n",
    "    assert round(calculate_distance_with_coords(from_coord, to_coord), 2) == 264.99\n",
    "\n",
    "\n",
    "    from_coord = (105, -122.4194)\n",
    "    to_coord = (34.0522, -118.2437) \n",
    "    assert calculate_distance_with_coords(from_coord, to_coord) == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function adds a new column with the distance between coordinates to the Dataframe.\n",
    "    The input is a dataframe and the output is the new dataframe \"\"\"\n",
    " \n",
    "def add_distance_column(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Apply the calculate_distance_with_coords function to each row of the DataFrame\n",
    "    distances = dataframe.apply(lambda row: calculate_distance_with_coords(\n",
    "        (row[\"pickup_latitude\"], row[\"pickup_longitude\"]),\n",
    "        (row[\"dropoff_latitude\"], row[\"dropoff_longitude\"])\n",
    "    ), axis=1)\n",
    "    \n",
    "    # Add the distances as a new column to the DataFrame\n",
    "    dataframe[\"distance\"] = distances\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "912a73d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' test - add_distance_column() '"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" test - add_distance_column() \"\"\"\n",
    "\n",
    "def add_distance_column_test():\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'pickup_latitude': [40.7128],\n",
    "        'pickup_longitude': [-74.006],\n",
    "        'dropoff_latitude': [40.7851],\n",
    "        'dropoff_longitude': [-73.9683]\n",
    "    })\n",
    "\n",
    "    df_with_distance = add_distance_column(df)\n",
    "\n",
    "    assert \"distance\" in df_with_distance.columns, 'distance column is not present'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function downloads all the relevant files from the taxi webpage\n",
    "    and places it into our local directory \"\"\"\n",
    "\n",
    "def download_files(month: int, year: int):\n",
    "    formatted_month = f\"{month:02d}\"\n",
    "    current_dir = os.getcwd()\n",
    "    url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{formatted_month}.parquet\"\n",
    "    \n",
    "    windows = f\"{current_dir}\\\\\"\n",
    "    str = windows if  os.name == 'nt' else \"\"\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(f\"{str}yellow_taxi_{year}_{formatted_month}.parquet\", \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=1024): \n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "years = list(range(2009, 2016))\n",
    "months = list(range(1, 13))\n",
    "\n",
    "for year in years:\n",
    "    if year < 2015:\n",
    "        for month in months:\n",
    "            download_files(month, year)\n",
    "    else:\n",
    "        for month in range(1, 7):\n",
    "            download_files(month, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "1dd682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function gets all the URLs from the taxi web page and returns\n",
    "    it as an array of strings \"\"\"\n",
    "\n",
    "def get_all_urls_from_taxi_page(taxi_page: str) -> list[str]:\n",
    "    try:\n",
    "        response = requests.get(taxi_page)\n",
    "\n",
    "        soup = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "        urls = []\n",
    "\n",
    "        for link in soup.find_all('a'):\n",
    "            href = link.get('href')\n",
    "            if href is not None:\n",
    "                urls.append(href)\n",
    "\n",
    "        return urls\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "9a7813aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\" test for get_all_urls_from_taxi_page() \"\"\"\n",
    "\n",
    "def get_all_urls_from_taxi_page_test():\n",
    "\n",
    "    assert len(get_all_urls_from_taxi_page(TAXI_URL)) == 483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function goes through all the URLs on the taxi web page\n",
    "    and returns only the ones ending in .parquet since we want\n",
    "    parquet files and also the ones from the years 2009 to 2015\n",
    "    to avoid iterating through unecessary files. \"\"\"\n",
    "\n",
    "def filter_taxi_parquet_urls(all_urls: list[str]) -> list[str]:\n",
    "    parquet_urls = []\n",
    "    years = list(range(2009, 2016))\n",
    "\n",
    "    if all_urls is not None:\n",
    "        for i in all_urls:\n",
    "            str = re.search('.parquet$', i)\n",
    "\n",
    "            if(str != None and \"yellow_tripdata\" in i):\n",
    "                year = int(i.split(\"_\")[2][:4])\n",
    "\n",
    "                if year in years:\n",
    "                    parquet_urls.append(i)\n",
    "    return parquet_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "08f83106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test for filter_taxi_parquet_urls() \"\"\"\n",
    "\n",
    "def filter_taxi_parquet_urls_test():\n",
    "\n",
    "    allUrlsData = get_all_urls_from_taxi_page(TAXI_URL)\n",
    "    assert len(filter_taxi_parquet_urls(allUrlsData)) == 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function takes a URL and extracts the month from it\n",
    "    The example url can look like:\n",
    "    https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet \"\"\"\n",
    "\n",
    "def get_and_clean_month(url: str) -> str:\n",
    "    str = url[len(url) - 10:]\n",
    "    [month, fileType] = str.split('.')\n",
    "    return month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "15238bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test for get_and_clean_month function \"\"\"\n",
    "\n",
    "def get_and_clean_month_test():\n",
    "\n",
    "    url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet'\n",
    "    assert get_and_clean_month(url) == '06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "f15da82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function takes a URL and extracts the year from it\n",
    "    The example url can look like:\n",
    "    https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet \"\"\"\n",
    "\n",
    "def get_and_clean_year(url: str) -> str:\n",
    "    str = url[len(url) - 15:]\n",
    "    [year, other] = str.split('-')\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "9aee9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test for get_and_clean_year function \"\"\"\n",
    "\n",
    "def get_and_clean_year_test():\n",
    "\n",
    "    url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet'\n",
    "    assert get_and_clean_year(url) == '2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "cd58b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This fucntion adds a new column with the distance between coordinates to the taxi Dataframe.\n",
    "    The input is a dataframe and the output is the new modified dataframe \"\"\"\n",
    " \n",
    "def add_distance_column_taxi(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Apply the calculate_distance_with_coords function to each row of the DataFrame\n",
    "    distances = dataframe.apply(lambda row: calculate_distance_with_coords(\n",
    "        (row[\"Start_Lat\"], row[\"Start_Lon\"]),\n",
    "        (row[\"End_Lat\"], row[\"End_Lon\"])\n",
    "    ), axis=1)\n",
    "    \n",
    "    # Add the distances as a new column to the DataFrame\n",
    "    dataframe[\"distance\"] = distances\n",
    "    \n",
    "    return dataframe[\"distance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82888d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test - add_distance_column_taxi() \"\"\"\n",
    "\n",
    "def add_distance_column_taxi_test():\n",
    "\n",
    "    df_taxi = pd.DataFrame({\n",
    "        'Start_Lat': [40.7128],\n",
    "        'Start_Lon': [-74.006],\n",
    "        'End_Lat': [40.7851],\n",
    "        'End_Lon': [-73.9683]\n",
    "    })\n",
    "\n",
    "    df_taxi_with_distance = add_distance_column_taxi(df_taxi)\n",
    "\n",
    "    assert df_taxi_with_distance.shape[0] == 1\n",
    "    assert isinstance(df_taxi_with_distance, pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function collects all the parquet urls from the taxi website.\n",
    "    It will then get the actual data from the parquet files and do various forms of cleaning.\n",
    "    For example, we will remove unnecessary columns and invalid data and will return\n",
    "    one gigantic dataframe with data from every month \"\"\"\n",
    "\n",
    "def convert_taxi_data(parquet_urls: list[str]) -> pd.DataFrame:\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    for parquet_url in parquet_urls:\n",
    "        month = get_and_clean_month(parquet_url)\n",
    "        year = get_and_clean_year(parquet_url)\n",
    "\n",
    "        cwd = os.getcwd()\n",
    "        files = os.listdir(cwd)\n",
    "\n",
    "        fileName = f\"yellow_taxi_{year}_{month}.parquet\"\n",
    "        if fileName in files :\n",
    "\n",
    "            dataframe = pd.read_parquet(fileName)\n",
    "            sample_dataframe = dataframe.sample(n=20000)\n",
    "            all_taxi_dataframes.append(sample_dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "200776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function gets all the urls from the taxi page, specifically the parquet urls,\n",
    "    gets and cleans it, and returns the valid data \"\"\"\n",
    "\n",
    "def get_taxi_data() -> pd.DataFrame:\n",
    "    all_urls = get_all_urls_from_taxi_page(TAXI_URL)\n",
    "    all_parquet_urls = filter_taxi_parquet_urls(all_urls)\n",
    "    taxi_data = convert_taxi_data(all_parquet_urls)\n",
    "\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "ac161e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/690674327.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/690674327.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/690674327.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/690674327.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/690674327.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/690674327.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/690674327.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/690674327.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/690674327.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/690674327.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/690674327.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Start_Lon</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>Fare_Amt</th>\n",
       "      <th>Tip_Amt</th>\n",
       "      <th>Total_Amt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9848492</th>\n",
       "      <td>2015-01-24 11:33:24</td>\n",
       "      <td>2015-01-24 11:39:27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>8.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4138542</th>\n",
       "      <td>2015-01-11 03:36:37</td>\n",
       "      <td>2015-01-11 03:46:48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195869</th>\n",
       "      <td>2015-01-06 23:06:32</td>\n",
       "      <td>2015-01-06 23:15:28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>12.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304062</th>\n",
       "      <td>2015-01-01 18:42:51</td>\n",
       "      <td>2015-01-01 18:46:40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.91</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997947</th>\n",
       "      <td>2015-01-13 10:08:03</td>\n",
       "      <td>2015-01-13 10:23:37</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14423524</th>\n",
       "      <td>2009-12-05 16:18:00</td>\n",
       "      <td>2009-12-05 16:29:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>-73.978557</td>\n",
       "      <td>40.783003</td>\n",
       "      <td>-73.952998</td>\n",
       "      <td>40.780155</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576801</th>\n",
       "      <td>2009-12-27 13:56:12</td>\n",
       "      <td>2009-12-27 14:08:04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-73.973485</td>\n",
       "      <td>40.779688</td>\n",
       "      <td>-73.986549</td>\n",
       "      <td>40.761371</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12997500</th>\n",
       "      <td>2009-12-30 21:00:00</td>\n",
       "      <td>2009-12-30 21:09:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>-73.972438</td>\n",
       "      <td>40.746262</td>\n",
       "      <td>-73.981550</td>\n",
       "      <td>40.724658</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8524081</th>\n",
       "      <td>2009-12-08 13:46:19</td>\n",
       "      <td>2009-12-08 14:01:50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>-73.992862</td>\n",
       "      <td>40.724189</td>\n",
       "      <td>-73.991038</td>\n",
       "      <td>40.761985</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5520466</th>\n",
       "      <td>2009-12-02 15:54:48</td>\n",
       "      <td>2009-12-02 16:02:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-73.989499</td>\n",
       "      <td>40.746177</td>\n",
       "      <td>-73.977284</td>\n",
       "      <td>40.754371</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.93</td>\n",
       "      <td>7.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1560000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tpep_pickup_datetime tpep_dropoff_datetime  Passenger_Count  \\\n",
       "9848492   2015-01-24 11:33:24   2015-01-24 11:39:27              2.0   \n",
       "4138542   2015-01-11 03:36:37   2015-01-11 03:46:48              1.0   \n",
       "2195869   2015-01-06 23:06:32   2015-01-06 23:15:28              1.0   \n",
       "304062    2015-01-01 18:42:51   2015-01-01 18:46:40              1.0   \n",
       "4997947   2015-01-13 10:08:03   2015-01-13 10:23:37              1.0   \n",
       "...                       ...                   ...              ...   \n",
       "14423524  2009-12-05 16:18:00   2009-12-05 16:29:00              1.0   \n",
       "576801    2009-12-27 13:56:12   2009-12-27 14:08:04              2.0   \n",
       "12997500  2009-12-30 21:00:00   2009-12-30 21:09:00              1.0   \n",
       "8524081   2009-12-08 13:46:19   2009-12-08 14:01:50              1.0   \n",
       "5520466   2009-12-02 15:54:48   2009-12-02 16:02:11              1.0   \n",
       "\n",
       "          Trip_Distance   Start_Lon   Start_Lat     End_Lon     End_Lat  \\\n",
       "9848492            0.91  100.000000  100.000000   50.000000   50.000000   \n",
       "4138542            1.80  264.000000  264.000000  264.000000  264.000000   \n",
       "2195869            1.90  229.000000  229.000000  107.000000  107.000000   \n",
       "304062             0.91  262.000000  262.000000  141.000000  141.000000   \n",
       "4997947            1.20  229.000000  229.000000  170.000000  170.000000   \n",
       "...                 ...         ...         ...         ...         ...   \n",
       "14423524           1.96  -73.978557   40.783003  -73.952998   40.780155   \n",
       "576801             1.60  -73.973485   40.779688  -73.986549   40.761371   \n",
       "12997500           1.90  -73.972438   40.746262  -73.981550   40.724658   \n",
       "8524081            3.40  -73.992862   40.724189  -73.991038   40.761985   \n",
       "5520466            1.10  -73.989499   40.746177  -73.977284   40.754371   \n",
       "\n",
       "          Fare_Amt  Tip_Amt  Total_Amt  \n",
       "9848492        6.0     1.70       8.50  \n",
       "4138542        9.5     0.00      10.80  \n",
       "2195869        9.0     2.06      12.36  \n",
       "304062         5.0     0.00       5.80  \n",
       "4997947       10.5     0.00      11.30  \n",
       "...            ...      ...        ...  \n",
       "14423524       8.1     2.00      10.60  \n",
       "576801         8.1     0.00       8.60  \n",
       "12997500       6.9     0.00       7.90  \n",
       "8524081       10.9     0.00      11.40  \n",
       "5520466        5.7     0.93       7.13  \n",
       "\n",
       "[1560000 rows x 11 columns]"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_cols = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance','PULocationID', 'DOLocationID','fare_amount','tip_amount','total_amount','pickup_datetime', 'dropoff_datetime', 'pickup_longitude', 'pickup_latitude',  'dropoff_longitude', 'dropoff_latitude', 'Trip_Pickup_DateTime', 'Trip_Dropoff_DateTime', 'Passenger_Count', 'Trip_Distance', 'Start_Lon', 'Start_Lat',  'End_Lon', 'End_Lat',  'Fare_Amt', 'Tip_Amt', 'Total_Amt']\n",
    "df_selected = taxi_data[selected_cols]\n",
    "# list of column pairs to join\n",
    "column_pairs = [(\"tpep_pickup_datetime\", 'pickup_datetime'), \n",
    "                (\"tpep_dropoff_datetime\", 'dropoff_datetime'),\n",
    "                ('Trip_Distance', 'trip_distance'),\n",
    "                ('Passenger_Count', 'passenger_count'),\n",
    "                ('Start_Lon', 'PULocationID'),\n",
    "                ('Start_Lat', 'PULocationID'),\n",
    "                ('End_Lon', 'DOLocationID'),\n",
    "                ('End_Lat', 'DOLocationID'),\n",
    "                ('Fare_Amt', 'fare_amount'),\n",
    "                ('Tip_Amt', 'tip_amount'),\n",
    "                ('Total_Amt', 'total_amount')]\n",
    "\n",
    "# loop over column pairs and join them\n",
    "for pair in column_pairs:\n",
    "    # fill missing values in the first column with values from the second column\n",
    "    df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
    "    # drop the second column\n",
    "    df_selected_final = df_selected.drop(pair[1], axis=1)\n",
    "\n",
    "df_selected_final = df_selected_final.drop(['pickup_datetime',\t'dropoff_datetime', 'passenger_count', 'trip_distance', 'PULocationID', 'DOLocationID', 'fare_amount', 'tip_amount', 'pickup_longitude',\t'pickup_latitude',\t'dropoff_longitude'\t,'dropoff_latitude'], axis=1)\n",
    "\n",
    "\n",
    "column_pairs = [(\"tpep_pickup_datetime\", 'Trip_Pickup_DateTime'), \n",
    "                (\"tpep_dropoff_datetime\", 'Trip_Dropoff_DateTime')]\n",
    "\n",
    "\n",
    "# loop over column pairs and join them\n",
    "for pair in column_pairs:\n",
    "    # fill missing values in the first column with values from the second column\n",
    "    df_selected_final[pair[0]] = df_selected_final[pair[0]].fillna(df_selected_final[pair[1]])\n",
    "    # drop the second column\n",
    "    df_selected_final = df_selected_final.drop(pair[1], axis=1)\n",
    "\n",
    "df_selected_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "486a8d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Start_Lon</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>Fare_Amt</th>\n",
       "      <th>Tip_Amt</th>\n",
       "      <th>Total_Amt</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-08 18:59:00</td>\n",
       "      <td>2009-01-08 18:56:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-74.006682</td>\n",
       "      <td>40.730838</td>\n",
       "      <td>-74.002757</td>\n",
       "      <td>40.721902</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.650120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-25 08:58:05</td>\n",
       "      <td>2009-01-25 09:05:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-73.950096</td>\n",
       "      <td>40.771146</td>\n",
       "      <td>-73.988383</td>\n",
       "      <td>40.731252</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.90</td>\n",
       "      <td>3.407997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-31 17:42:00</td>\n",
       "      <td>2009-01-31 17:46:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-73.955762</td>\n",
       "      <td>40.777910</td>\n",
       "      <td>-73.953743</td>\n",
       "      <td>40.785117</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.508456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-14 23:16:00</td>\n",
       "      <td>2009-01-14 23:26:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>-74.013782</td>\n",
       "      <td>40.708917</td>\n",
       "      <td>-73.983182</td>\n",
       "      <td>40.720977</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.00</td>\n",
       "      <td>1.809341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-27 14:22:58</td>\n",
       "      <td>2009-01-27 14:27:25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-73.962517</td>\n",
       "      <td>40.767187</td>\n",
       "      <td>-73.954747</td>\n",
       "      <td>40.765823</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.418364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233456</th>\n",
       "      <td>2009-12-05 16:18:00</td>\n",
       "      <td>2009-12-05 16:29:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.96</td>\n",
       "      <td>-73.978557</td>\n",
       "      <td>40.783003</td>\n",
       "      <td>-73.952998</td>\n",
       "      <td>40.780155</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.60</td>\n",
       "      <td>1.354932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233457</th>\n",
       "      <td>2009-12-27 13:56:12</td>\n",
       "      <td>2009-12-27 14:08:04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.60</td>\n",
       "      <td>-73.973485</td>\n",
       "      <td>40.779688</td>\n",
       "      <td>-73.986549</td>\n",
       "      <td>40.761371</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.60</td>\n",
       "      <td>1.437776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233458</th>\n",
       "      <td>2009-12-30 21:00:00</td>\n",
       "      <td>2009-12-30 21:09:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.90</td>\n",
       "      <td>-73.972438</td>\n",
       "      <td>40.746262</td>\n",
       "      <td>-73.981550</td>\n",
       "      <td>40.724658</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.90</td>\n",
       "      <td>1.565572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233459</th>\n",
       "      <td>2009-12-08 13:46:19</td>\n",
       "      <td>2009-12-08 14:01:50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.40</td>\n",
       "      <td>-73.992862</td>\n",
       "      <td>40.724189</td>\n",
       "      <td>-73.991038</td>\n",
       "      <td>40.761985</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.40</td>\n",
       "      <td>2.609779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233460</th>\n",
       "      <td>2009-12-02 15:54:48</td>\n",
       "      <td>2009-12-02 16:02:11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-73.989499</td>\n",
       "      <td>40.746177</td>\n",
       "      <td>-73.977284</td>\n",
       "      <td>40.754371</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.93</td>\n",
       "      <td>7.13</td>\n",
       "      <td>0.854728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>233461 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime    dropoff_datetime  Passenger_Count  \\\n",
       "0      2009-01-08 18:59:00 2009-01-08 18:56:00              2.0   \n",
       "1      2009-01-25 08:58:05 2009-01-25 09:05:49              1.0   \n",
       "2      2009-01-31 17:42:00 2009-01-31 17:46:00              5.0   \n",
       "3      2009-01-14 23:16:00 2009-01-14 23:26:00              1.0   \n",
       "4      2009-01-27 14:22:58 2009-01-27 14:27:25              1.0   \n",
       "...                    ...                 ...              ...   \n",
       "233456 2009-12-05 16:18:00 2009-12-05 16:29:00              1.0   \n",
       "233457 2009-12-27 13:56:12 2009-12-27 14:08:04              2.0   \n",
       "233458 2009-12-30 21:00:00 2009-12-30 21:09:00              1.0   \n",
       "233459 2009-12-08 13:46:19 2009-12-08 14:01:50              1.0   \n",
       "233460 2009-12-02 15:54:48 2009-12-02 16:02:11              1.0   \n",
       "\n",
       "        Trip_Distance  Start_Lon  Start_Lat    End_Lon    End_Lat  Fare_Amt  \\\n",
       "0                0.89 -74.006682  40.730838 -74.002757  40.721902       4.9   \n",
       "1                4.00 -73.950096  40.771146 -73.988383  40.731252      10.9   \n",
       "2                0.86 -73.955762  40.777910 -73.953743  40.785117       4.5   \n",
       "3                3.05 -74.013782  40.708917 -73.983182  40.720977      10.5   \n",
       "4                0.40 -73.962517  40.767187 -73.954747  40.765823       3.7   \n",
       "...               ...        ...        ...        ...        ...       ...   \n",
       "233456           1.96 -73.978557  40.783003 -73.952998  40.780155       8.1   \n",
       "233457           1.60 -73.973485  40.779688 -73.986549  40.761371       8.1   \n",
       "233458           1.90 -73.972438  40.746262 -73.981550  40.724658       6.9   \n",
       "233459           3.40 -73.992862  40.724189 -73.991038  40.761985      10.9   \n",
       "233460           1.10 -73.989499  40.746177 -73.977284  40.754371       5.7   \n",
       "\n",
       "        Tip_Amt  Total_Amt  distance  \n",
       "0          2.00       7.90  0.650120  \n",
       "1          0.00      10.90  3.407997  \n",
       "2          0.00       4.50  0.508456  \n",
       "3          2.00      13.00  1.809341  \n",
       "4          0.00       3.70  0.418364  \n",
       "...         ...        ...       ...  \n",
       "233456     2.00      10.60  1.354932  \n",
       "233457     0.00       8.60  1.437776  \n",
       "233458     0.00       7.90  1.565572  \n",
       "233459     0.00      11.40  2.609779  \n",
       "233460     0.93       7.13  0.854728  \n",
       "\n",
       "[233461 rows x 12 columns]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "We then filter based on coordinates to make sure the rides are within the coordinates we want.\n",
    "We also remove trips with 0 passangers and no fares. We further remove trips with passangers above 6 as that \n",
    "is uber policy. Lastly we remove trips with no distace between dropoff and pickup. The output is the\n",
    "cleaned dataframe\n",
    "'''\n",
    "\n",
    "df_selected_final = df_selected_final[(df_selected_final[\"Start_Lat\"] >= 40.560445) & \n",
    "                                      (df_selected_final[\"Start_Lon\"] >= -74.242330) & \n",
    "                                      (df_selected_final[\"Start_Lat\"] <= 40.908524) & \n",
    "                                      (df_selected_final[\"Start_Lon\"] <= -73.717047) &\n",
    "                                      (df_selected_final[\"End_Lat\"] >= 40.560445) & \n",
    "                                      (df_selected_final[\"End_Lon\"] >= -74.242330) & \n",
    "                                      (df_selected_final[\"End_Lat\"] <= 40.908524) & \n",
    "                                      (df_selected_final[\"End_Lon\"] <= -73.717047)]\n",
    "\n",
    "\n",
    "df_selected_final = df_selected_final[df_selected_final['Passenger_Count'] != 0]\n",
    "\n",
    "add_distance_column_taxi(df_selected_final)\n",
    "\n",
    "df_selected_final = df_selected_final.drop(index=df_selected_final[df_selected_final['distance'] == 0].index)\n",
    "\n",
    "df_selected_final = df_selected_final[df_selected_final['Passenger_Count']<=6.0]\n",
    "df_selected_final = df_selected_final.reset_index(drop=True)\n",
    "df_selected_final = df_selected_final.rename(columns={\n",
    "    \"tpep_pickup_datetime\": \"pickup_datetime\",\n",
    "    \"tpep_dropoff_datetime\": \"dropoff_datetime\",\n",
    "    \"Passenger_Count\": \"Passenger_Count\",\n",
    "    \"Trip_Distance\": \"Trip_Distance\",\n",
    "    \"Start_Lon\": \"Start_Lon\",\n",
    "    \"Start_Lat\": \"Start_Lat\",\n",
    "    \"End_Lon\": \"End_Lon\",\n",
    "    \"End_Lat\": \"End_Lat\",\n",
    "    \"Fare_Amt\": \"Fare_Amt\",\n",
    "    \"Tip_Amt\": \"Tip_Amt\",\n",
    "    \"Total_Amt\": \"Total_Amt\",\n",
    "    \"distance\": \"distance\"\n",
    "})\n",
    "\n",
    "df_selected_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "e3d6fd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Start_Lon</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>Fare_Amt</th>\n",
       "      <th>Tip_Amt</th>\n",
       "      <th>Total_Amt</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-08 18:59:00</td>\n",
       "      <td>2009-01-08 18:56:00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>-74.006682</td>\n",
       "      <td>40.730838</td>\n",
       "      <td>-74.002757</td>\n",
       "      <td>40.721902</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.650120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-25 08:58:05</td>\n",
       "      <td>2009-01-25 09:05:49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>-73.950096</td>\n",
       "      <td>40.771146</td>\n",
       "      <td>-73.988383</td>\n",
       "      <td>40.731252</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.9</td>\n",
       "      <td>3.407997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-31 17:42:00</td>\n",
       "      <td>2009-01-31 17:46:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-73.955762</td>\n",
       "      <td>40.777910</td>\n",
       "      <td>-73.953743</td>\n",
       "      <td>40.785117</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.508456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-14 23:16:00</td>\n",
       "      <td>2009-01-14 23:26:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.05</td>\n",
       "      <td>-74.013782</td>\n",
       "      <td>40.708917</td>\n",
       "      <td>-73.983182</td>\n",
       "      <td>40.720977</td>\n",
       "      <td>10.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.809341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-27 14:22:58</td>\n",
       "      <td>2009-01-27 14:27:25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-73.962517</td>\n",
       "      <td>40.767187</td>\n",
       "      <td>-73.954747</td>\n",
       "      <td>40.765823</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.418364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pickup_datetime    dropoff_datetime  Passenger_Count  Trip_Distance  \\\n",
       "0 2009-01-08 18:59:00 2009-01-08 18:56:00              2.0           0.89   \n",
       "1 2009-01-25 08:58:05 2009-01-25 09:05:49              1.0           4.00   \n",
       "2 2009-01-31 17:42:00 2009-01-31 17:46:00              5.0           0.86   \n",
       "3 2009-01-14 23:16:00 2009-01-14 23:26:00              1.0           3.05   \n",
       "4 2009-01-27 14:22:58 2009-01-27 14:27:25              1.0           0.40   \n",
       "\n",
       "   Start_Lon  Start_Lat    End_Lon    End_Lat  Fare_Amt  Tip_Amt  Total_Amt  \\\n",
       "0 -74.006682  40.730838 -74.002757  40.721902       4.9      2.0        7.9   \n",
       "1 -73.950096  40.771146 -73.988383  40.731252      10.9      0.0       10.9   \n",
       "2 -73.955762  40.777910 -73.953743  40.785117       4.5      0.0        4.5   \n",
       "3 -74.013782  40.708917 -73.983182  40.720977      10.5      2.0       13.0   \n",
       "4 -73.962517  40.767187 -73.954747  40.765823       3.7      0.0        3.7   \n",
       "\n",
       "   distance  \n",
       "0  0.650120  \n",
       "1  3.407997  \n",
       "2  0.508456  \n",
       "3  1.809341  \n",
       "4  0.418364  "
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Taxi_Data = df_selected_final.copy()\n",
    "Taxi_Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function first loads the uber data from the csv file. \n",
    "We then filter based on coordinates to make sure the rides are within the coordinates we want.\n",
    "We also remove trips with 0 passangers and no fares. We further remove trips with passangers above 6 as that \n",
    "is uber policy. Lastly we remove trips with no distace between dropoff and pickup. The output is the\n",
    "cleaned dataframe\"\"\"\n",
    "\n",
    "def load_and_clean_uber_data(csv_file: str) -> pd.DataFrame:\n",
    "\n",
    "    # Reading in file into a data frame \n",
    "    uber_data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Filter data based on pickup and dropoff latitude/longitude(40.560445, -74.242330) and (40.908524, -73.717047).\n",
    "\n",
    "    uber_data = uber_data[(uber_data[\"pickup_latitude\"] >= 40.560445) & \n",
    "                      (uber_data[\"pickup_longitude\"] >= -74.242330) & \n",
    "                      (uber_data[\"pickup_latitude\"] <= 40.908524) & \n",
    "                      (uber_data[\"pickup_longitude\"] <= -73.717047) &\n",
    "                      (uber_data[\"dropoff_latitude\"] >= 40.560445) & \n",
    "                      (uber_data[\"dropoff_longitude\"] >= -74.242330) & \n",
    "                      (uber_data[\"dropoff_latitude\"] <= 40.908524) & \n",
    "                      (uber_data[\"dropoff_longitude\"] <= -73.717047)]\n",
    "    \n",
    "    # Checking if there are any null values for pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude\n",
    "    null_drop_lat = uber_data[uber_data['dropoff_latitude'].isnull()]\n",
    "    null_drop_long = uber_data[uber_data['dropoff_longitude'].isnull()]\n",
    "    null_pick_lat= uber_data[uber_data['pickup_latitude'].isnull()]\n",
    "    null_pick_long = uber_data[uber_data['pickup_longitude'].isnull()]\n",
    "\n",
    "    # Return True, if none of the colums have null values \n",
    "\n",
    "   # if null_drop_lat.empty & null_drop_long.empty & null_pick_lat.empty & null_pick_long.empty :\n",
    "        #print(True)\n",
    "    #else:\n",
    "       # print(False)\n",
    "\n",
    "    \n",
    "    # Removing rows where passamger count is 0 \n",
    "    uber_data = uber_data[uber_data['passenger_count']!=0]\n",
    "\n",
    "\n",
    "    # Removing rows with passanger data is abnormally large \n",
    "    uber_data = uber_data[uber_data['passenger_count']<=6]\n",
    "\n",
    "    # Checking datatypes for all columns \n",
    "    #print(uber_data.dtypes)\n",
    "\n",
    "    #Making sure pickup time is a datetime object and normalizing the name \n",
    "    uber_data ['pickup_time'] = pd.to_datetime(uber_data ['pickup_datetime'])\n",
    " \n",
    "    return uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "90d2ceba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24238194</td>\n",
       "      <td>2015-05-07 19:52:06.0000003</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27835199</td>\n",
       "      <td>2009-07-17 20:04:56.0000002</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44984355</td>\n",
       "      <td>2009-08-24 21:45:00.00000061</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25894730</td>\n",
       "      <td>2009-06-26 08:22:21.0000001</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17610152</td>\n",
       "      <td>2014-08-28 17:47:00.000000188</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>42598914</td>\n",
       "      <td>2012-10-28 10:49:00.00000053</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-10-28 10:49:00 UTC</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>16382965</td>\n",
       "      <td>2014-03-14 01:09:00.0000008</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-03-14 01:09:00 UTC</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>27804658</td>\n",
       "      <td>2009-06-29 00:42:00.00000078</td>\n",
       "      <td>30.9</td>\n",
       "      <td>2009-06-29 00:42:00 UTC</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>20259894</td>\n",
       "      <td>2015-05-20 14:56:25.0000004</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2015-05-20 14:56:25 UTC</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>11951496</td>\n",
       "      <td>2010-05-15 04:08:00.00000076</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2010-05-15 04:08:00 UTC</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194786 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                            key  fare_amount  \\\n",
       "0         24238194    2015-05-07 19:52:06.0000003          7.5   \n",
       "1         27835199    2009-07-17 20:04:56.0000002          7.7   \n",
       "2         44984355   2009-08-24 21:45:00.00000061         12.9   \n",
       "3         25894730    2009-06-26 08:22:21.0000001          5.3   \n",
       "4         17610152  2014-08-28 17:47:00.000000188         16.0   \n",
       "...            ...                            ...          ...   \n",
       "199995    42598914   2012-10-28 10:49:00.00000053          3.0   \n",
       "199996    16382965    2014-03-14 01:09:00.0000008          7.5   \n",
       "199997    27804658   2009-06-29 00:42:00.00000078         30.9   \n",
       "199998    20259894    2015-05-20 14:56:25.0000004         14.5   \n",
       "199999    11951496   2010-05-15 04:08:00.00000076         14.1   \n",
       "\n",
       "                pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0       2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
       "1       2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
       "2       2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
       "3       2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
       "4       2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
       "...                         ...               ...              ...   \n",
       "199995  2012-10-28 10:49:00 UTC        -73.987042        40.739367   \n",
       "199996  2014-03-14 01:09:00 UTC        -73.984722        40.736837   \n",
       "199997  2009-06-29 00:42:00 UTC        -73.986017        40.756487   \n",
       "199998  2015-05-20 14:56:25 UTC        -73.997124        40.725452   \n",
       "199999  2010-05-15 04:08:00 UTC        -73.984395        40.720077   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0              -73.999512         40.723217                1   \n",
       "1              -73.994710         40.750325                1   \n",
       "2              -73.962565         40.772647                1   \n",
       "3              -73.965316         40.803349                3   \n",
       "4              -73.973082         40.761247                5   \n",
       "...                   ...               ...              ...   \n",
       "199995         -73.986525         40.740297                1   \n",
       "199996         -74.006672         40.739620                1   \n",
       "199997         -73.858957         40.692588                2   \n",
       "199998         -73.983215         40.695415                1   \n",
       "199999         -73.985508         40.768793                1   \n",
       "\n",
       "                     pickup_time  \n",
       "0      2015-05-07 19:52:06+00:00  \n",
       "1      2009-07-17 20:04:56+00:00  \n",
       "2      2009-08-24 21:45:00+00:00  \n",
       "3      2009-06-26 08:22:21+00:00  \n",
       "4      2014-08-28 17:47:00+00:00  \n",
       "...                          ...  \n",
       "199995 2012-10-28 10:49:00+00:00  \n",
       "199996 2014-03-14 01:09:00+00:00  \n",
       "199997 2009-06-29 00:42:00+00:00  \n",
       "199998 2015-05-20 14:56:25+00:00  \n",
       "199999 2010-05-15 04:08:00+00:00  \n",
       "\n",
       "[194786 rows x 10 columns]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_clean_uber_data(\"uber_rides_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" We use the add distance column fcuntion we had defined before to add a new column with the distance \n",
    "of the ride to our uber data. We also drop columns where the distance of the ride is ==0\"\"\"\n",
    "\n",
    "def get_uber_data() -> pd.DataFrame:\n",
    "    uber_dataframe = load_and_clean_uber_data(\"uber_rides_sample.csv\")\n",
    "    add_distance_column(uber_dataframe)\n",
    "    uber_dataframe = uber_dataframe.drop(index=uber_dataframe[uber_dataframe['distance'] == 0].index)\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "9c2bd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "826a4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unnecessary columns \n",
    "final_uber_data = final_uber_data.drop('Unnamed: 0', axis=1)\n",
    "final_uber_data = final_uber_data.drop('key', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "339997e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>1.044594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>1.525071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>3.131464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>1.032372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>2.786061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-10-28 10:49:00 UTC</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "      <td>0.069673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-03-14 01:09:00 UTC</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "      <td>1.167951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>30.9</td>\n",
       "      <td>2009-06-29 00:42:00 UTC</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "      <td>7.995752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>14.5</td>\n",
       "      <td>2015-05-20 14:56:25 UTC</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "      <td>2.197512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>14.1</td>\n",
       "      <td>2010-05-15 04:08:00 UTC</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "      <td>3.362040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192829 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount          pickup_datetime  pickup_longitude  \\\n",
       "0               7.5  2015-05-07 19:52:06 UTC        -73.999817   \n",
       "1               7.7  2009-07-17 20:04:56 UTC        -73.994355   \n",
       "2              12.9  2009-08-24 21:45:00 UTC        -74.005043   \n",
       "3               5.3  2009-06-26 08:22:21 UTC        -73.976124   \n",
       "4              16.0  2014-08-28 17:47:00 UTC        -73.925023   \n",
       "...             ...                      ...               ...   \n",
       "199995          3.0  2012-10-28 10:49:00 UTC        -73.987042   \n",
       "199996          7.5  2014-03-14 01:09:00 UTC        -73.984722   \n",
       "199997         30.9  2009-06-29 00:42:00 UTC        -73.986017   \n",
       "199998         14.5  2015-05-20 14:56:25 UTC        -73.997124   \n",
       "199999         14.1  2010-05-15 04:08:00 UTC        -73.984395   \n",
       "\n",
       "        pickup_latitude  dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0             40.738354         -73.999512         40.723217                1   \n",
       "1             40.728225         -73.994710         40.750325                1   \n",
       "2             40.740770         -73.962565         40.772647                1   \n",
       "3             40.790844         -73.965316         40.803349                3   \n",
       "4             40.744085         -73.973082         40.761247                5   \n",
       "...                 ...                ...               ...              ...   \n",
       "199995        40.739367         -73.986525         40.740297                1   \n",
       "199996        40.736837         -74.006672         40.739620                1   \n",
       "199997        40.756487         -73.858957         40.692588                2   \n",
       "199998        40.725452         -73.983215         40.695415                1   \n",
       "199999        40.720077         -73.985508         40.768793                1   \n",
       "\n",
       "                     pickup_time  distance  \n",
       "0      2015-05-07 19:52:06+00:00  1.044594  \n",
       "1      2009-07-17 20:04:56+00:00  1.525071  \n",
       "2      2009-08-24 21:45:00+00:00  3.131464  \n",
       "3      2009-06-26 08:22:21+00:00  1.032372  \n",
       "4      2014-08-28 17:47:00+00:00  2.786061  \n",
       "...                          ...       ...  \n",
       "199995 2012-10-28 10:49:00+00:00  0.069673  \n",
       "199996 2014-03-14 01:09:00+00:00  1.167951  \n",
       "199997 2009-06-29 00:42:00+00:00  7.995752  \n",
       "199998 2015-05-20 14:56:25+00:00  2.197512  \n",
       "199999 2010-05-15 04:08:00+00:00  3.362040  \n",
       "\n",
       "[192829 rows x 9 columns]"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_uber_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function takes all the weather files, iterates through them and merges them \n",
    "into one dataframe. The output is the combined dataframe\"\"\"\n",
    "\n",
    "def get_all_weather_csvs() -> pd.DataFrame:\n",
    "    years = list(range(2009, 2016))\n",
    "\n",
    "    # Initialize an empty list to store the dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    # Iterate over the weather files\n",
    "    for year in years:\n",
    "        filepath = f\"{year}_weather.csv\"\n",
    "        df = pd.read_csv(filepath)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Concatenate all the dataframes into a single dataframe\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "fb7e80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function first loads the uber data from the csv file. \n",
    "We then filter based on coordinates to make sure the rides are within the coordinates we want.\n",
    "We also remove trips with 0 passangers and no fares. We further remove trips with passangers above 6 as that \n",
    "is uber policy. Lastly we remove trips with no distace between dropoff and pickup. The output is the\n",
    "cleaned dataframe\"\"\"\n",
    "\n",
    "def load_and_clean_weather_data() -> pd.DataFrame:\n",
    "\n",
    "    df = get_all_weather_csvs()\n",
    "\n",
    "    df1 = df[['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'NAME','HourlyPrecipitation','HourlyWindGustSpeed', 'HourlyWindSpeed', 'DailyAverageWindSpeed','DailyPrecipitation']]\n",
    "    df2 = df1.dropna(subset=['HourlyPrecipitation', 'HourlyWindGustSpeed'])\n",
    "\n",
    "    #column_types = df2.dtypes\n",
    "\n",
    "    #print(column_types)\n",
    "\n",
    "    # we see that the averages for wind speed and precipitation are null for all values so we can drop the columns \n",
    "\n",
    "    # We also doing need the hourly wind gust speed as we will be using the hourly wind speed, we can drop that column as well\n",
    "\n",
    "    df2 = df2.drop(columns=['DailyAverageWindSpeed','DailyPrecipitation', 'HourlyWindGustSpeed','LATITUDE', 'LONGITUDE'])\n",
    "    df2['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "    df2\n",
    "\n",
    "    # Removing all rows where Hourly preicipitation has the value \"T\" as we do not need to measure trace amounts \n",
    "\n",
    "    df3 = df2[df2['HourlyPrecipitation'] != \"T\"]\n",
    "\n",
    "    df4 = df3.drop(columns=[\"STATION\"])\n",
    "\n",
    "    df4 = df4.reset_index()\n",
    "\n",
    "    df4['DATE'] = df4['DATE'].apply(lambda x: x.to_pydatetime())\n",
    "\n",
    "    df4['DATE'] = pd.to_datetime(df4['DATE'])\n",
    "\n",
    "    df4['HourlyPrecipitation'] = df4['HourlyPrecipitation'].str.replace(r'(\\d+)\\s*[sS]$', r'\\1', regex=True)\n",
    "    \n",
    "    # convert column \"A\" from object to float\n",
    "    df4['HourlyPrecipitation'] = df4['HourlyPrecipitation'].astype(float)\n",
    "\n",
    "    Weather_Data = df4.drop('index', axis=1)\n",
    "\n",
    "    return  Weather_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "7a3a9156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-06 20:00:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-06 23:38:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-07 02:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-07 03:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.06</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-07 04:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.07</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>2015-12-29 10:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>2015-12-29 11:33:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>2015-12-29 11:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>2015-12-31 11:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>2015-12-31 20:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7103 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DATE                         NAME  HourlyPrecipitation  \\\n",
       "0    2009-01-06 20:00:00  NY CITY CENTRAL PARK, NY US                 0.01   \n",
       "1    2009-01-06 23:38:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "2    2009-01-07 02:51:00  NY CITY CENTRAL PARK, NY US                 0.09   \n",
       "3    2009-01-07 03:51:00  NY CITY CENTRAL PARK, NY US                 0.06   \n",
       "4    2009-01-07 04:51:00  NY CITY CENTRAL PARK, NY US                 0.07   \n",
       "...                  ...                          ...                  ...   \n",
       "7098 2015-12-29 10:51:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "7099 2015-12-29 11:33:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "7100 2015-12-29 11:51:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "7101 2015-12-31 11:51:00  NY CITY CENTRAL PARK, NY US                 0.00   \n",
       "7102 2015-12-31 20:51:00  NY CITY CENTRAL PARK, NY US                 0.00   \n",
       "\n",
       "      HourlyWindSpeed  \n",
       "0                10.0  \n",
       "1                11.0  \n",
       "2                13.0  \n",
       "3                15.0  \n",
       "4                16.0  \n",
       "...               ...  \n",
       "7098             10.0  \n",
       "7099              8.0  \n",
       "7100              6.0  \n",
       "7101              9.0  \n",
       "7102             10.0  \n",
       "\n",
       "[7103 rows x 4 columns]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Roll up the data to daily\"\"\"\n",
    "def clean_month_weather_data_daily() -> pd.DataFrame:\n",
    "\n",
    "    daily_data = load_and_clean_weather_data()\n",
    "\n",
    "    daily_data_final = daily_data.groupby([daily_data['DATE'].dt.year, daily_data['DATE'].dt.month, daily_data['DATE'].dt.day]).sum()[['HourlyPrecipitation', \"HourlyWindSpeed\" ]]\n",
    "\n",
    "    daily_data_final = daily_data_final.rename_axis(index=['Year', 'Month', 'Day'])\n",
    "    \n",
    "    return daily_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "e3e6f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly() -> pd.DataFrame:\n",
    "\n",
    "    hourly_data = load_and_clean_weather_data()\n",
    "\n",
    "    hourly_data_final = hourly_data.groupby([hourly_data['DATE'].dt.year, hourly_data['DATE'].dt.month, hourly_data['DATE'].dt.day, hourly_data['DATE'].dt.hour]).sum()[['HourlyPrecipitation', \"HourlyWindSpeed\" ]]\n",
    "\n",
    "    hourly_data_final = hourly_data_final.rename_axis(index=['Year', 'Month', 'Day', 'Hour'])\n",
    "    \n",
    "    return hourly_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "48216557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2009</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>20</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.02</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">7</th>\n",
       "      <th>2</th>\n",
       "      <td>0.09</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.07</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     HourlyPrecipitation  HourlyWindSpeed\n",
       "Year Month Day Hour                                      \n",
       "2009 1     6   20                   0.01             10.0\n",
       "               23                   0.02             11.0\n",
       "           7   2                    0.09             13.0\n",
       "               3                    0.06             15.0\n",
       "               4                    0.07             16.0"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data = clean_month_weather_data_hourly()\n",
    "hourly_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "4cb386ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_7853/1094114271.py:13: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.13</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.26</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.69</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.75</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Month  Day  HourlyPrecipitation  HourlyWindSpeed\n",
       "0     2009      1    6                 0.03             21.0\n",
       "1     2009      1    7                 1.13            224.0\n",
       "2     2009      1   10                 0.06             48.0\n",
       "3     2009      1   11                 0.26             67.0\n",
       "4     2009      1   17                 0.69              7.0\n",
       "...    ...    ...  ...                  ...              ...\n",
       "1026  2015     12   26                 0.00             76.0\n",
       "1027  2015     12   27                 0.02             58.0\n",
       "1028  2015     12   28                 0.00             70.0\n",
       "1029  2015     12   29                 0.75            167.0\n",
       "1030  2015     12   31                 0.00             19.0\n",
       "\n",
       "[1031 rows x 5 columns]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data = clean_month_weather_data_daily()\n",
    "daily_weather_data = daily_weather_data.reset_index()\n",
    "\n",
    "daily_weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS HOURLY_WEATHER (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        year INTEGER,\n",
    "        month INTEGER,\n",
    "        day INTEGER,\n",
    "        hour INTEGER,\n",
    "        precipitation REAL,\n",
    "        wind REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS DAILY_WEATHER (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        year INTEGER,\n",
    "        month INTEGER,\n",
    "        day INTEGER,\n",
    "        precipitation REAL,\n",
    "        wind REAL\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS TAXI_TRIPS (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        pickup_datetime TEXT,\n",
    "        dropoff_datetime TEXT,\n",
    "        Passenger_Count REAL\n",
    "        Trip_Distance REAL,\n",
    "        Start_Lon REAL,\n",
    "        Start_Lat REAL,\n",
    "        End_Lon REAL, \n",
    "        End_Lat REAL,\n",
    "        Fare_Amt REAL, \n",
    "        Tip_Amt REAL, \n",
    "        Total_Amt REAL,\n",
    "        distance REAL,\n",
    "\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS UBER_TRIPS (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        pickup_datetime TEXT,\n",
    "        pickup_longitude REAL,\n",
    "        pickup_latitude REAL,\n",
    "        dropoff_longitude REAL,\n",
    "        dropoff_latitude REAL,\n",
    "        fare_amount REAL,\n",
    "        distance REAL,\n",
    "        passenger_count INTEGER,\n",
    "    );\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table():\n",
    "\n",
    "    hourly_weather_data.to_sql(name='HOURLY_WEATHER', con=engine, if_exists='replace', index=False)\n",
    "    daily_weather_data.to_sql(name='DAILY_WEATHER', con=engine, if_exists='replace', index=False)\n",
    "    final_uber_data.to_sql(name='UBER_TRIPS', con=engine, if_exists='replace', index=False)\n",
    "    Taxi_Data.to_sql(name='TAXI_TRIPS', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "write_dataframes_to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "8e495251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2009-01-08 18:59:00.000000', '2009-01-08 18:56:00.000000', 2.0, 0.89, -74.006682, 40.730838, -74.002757, 40.721902, 4.9, 2.0, 7.9, 0.6501198071814656)\n",
      "('2009-01-25 08:58:05.000000', '2009-01-25 09:05:49.000000', 1.0, 4.0, -73.950096, 40.771146, -73.988383, 40.731252, 10.9, 0.0, 10.9, 3.4079967267271756)\n",
      "('2009-01-31 17:42:00.000000', '2009-01-31 17:46:00.000000', 5.0, 0.8599999999999999, -73.95576199999998, 40.77791, -73.953743, 40.785117, 4.5, 0.0, 4.5, 0.5084556287120133)\n",
      "('2009-01-14 23:16:00.000000', '2009-01-14 23:26:00.000000', 1.0, 3.05, -74.013782, 40.708917, -73.983182, 40.720977, 10.5, 2.0, 13.0, 1.8093409706638137)\n",
      "('2009-01-27 14:22:58.000000', '2009-01-27 14:27:25.000000', 1.0, 0.4, -73.962517, 40.767187, -73.954747, 40.765823, 3.7, 0.0, 3.7, 0.4183639696584237)\n",
      "('2009-01-25 04:16:11.000000', '2009-01-25 04:43:02.000000', 1.0, 5.0, -73.948289, 40.778152, -74.00009799999998, 40.761239, 18.6, 15.0, 33.6, 2.957901935627818)\n",
      "('2009-01-24 21:32:08.000000', '2009-01-24 21:40:38.000000', 2.0, 1.7, -73.975696, 40.744693, -73.969436, 40.764367, 7.4, 0.0, 7.4, 1.3967347314316954)\n",
      "('2009-01-06 23:10:19.000000', '2009-01-06 23:17:53.000000', 1.0, 1.7, -73.95563799999998, 40.772558, -73.974361, 40.758063, 7.4, 0.0, 7.4, 1.4018847693020984)\n",
      "('2009-01-04 16:55:00.000000', '2009-01-04 17:08:00.000000', 5.0, 2.62, -73.967398, 40.75632, -73.945813, 40.781748, 9.3, 0.0, 9.3, 2.088281388956489)\n",
      "('2009-01-27 17:07:00.000000', '2009-01-27 17:15:00.000000', 5.0, 1.4, -73.999825, 40.761293, -73.983198, 40.764422, 6.5, 0.0, 7.5, 0.8986759710344573)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "query = \"SELECT * FROM TAXI_TRIPS LIMIT 10;\"\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "\n",
    "with open('1_hour_day.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3725eb44",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fbf5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "\n",
    "with open('2_day_week.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d53f383c",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b9a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "\n",
    "with open('3_95_percentile.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59638822",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417b0fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "\n",
    "with open('4_top_10_days.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12a1fc3e",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "\n",
    "with open('5_10_windiest_days.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5b5a047",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eea1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6 = \"\"\"\n",
    "    SELECT strftime('%w', pickup_datetime) AS day_of_week, COUNT(*) AS frequency\n",
    "    FROM UBER_TRIPS\n",
    "    WHERE pickup_datetime BETWEEN '2009-01-01 00:00:00 UTC' AND '2015-06-30 23:59:59 UTC'\n",
    "    GROUP BY day_of_week\n",
    "    ORDER BY day_of_week;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequency_hour(dataframe: pd.DataFrame):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    hour = [1, 2, 3, 4, 5]\n",
    "    values = [1, 5, 3, 2, 5]\n",
    "\n",
    "    axes.bar(hour, values)\n",
    "\n",
    "    axes.set_ylabel('Popularity')\n",
    "    axes.set_xlabel('Hour')\n",
    "    axes.set_title(\"Frequency per Hour\")\n",
    "    axes.set_xlim(-1, 11)\n",
    "    axes.set_ylim(-1.5, 1.5)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_frequency_hour():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_frequency_hour()\n",
    "plot_frequency_hour(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c350a277",
   "metadata": {},
   "source": [
    "### Visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "c02eeb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_distance_month(dataframe: pd.DataFrame):\n",
    "    figure, axes = plt.subplots(figsize=(30, 20))\n",
    "    \n",
    "    month = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "    distance = [1, 5, 3, 2, 5, 7, 8, 1, 9, 23, 6, 7]\n",
    "\n",
    "    x = np.linspace(0, 12, 12) \n",
    "\n",
    "    a, b = np.polyfit(x, distance, deg=1)\n",
    "    y_est = a * x + b\n",
    "    y_err = x.std() * np.sqrt(1/len(x) +\n",
    "                            (x - x.mean())**2 / np.sum((x - x.mean())**2))\n",
    "\n",
    "    axes.plot(x, y_est, '-')\n",
    "\n",
    "    axes.plot(month, distance, 'o', color='tab:brown')\n",
    "    axes.fill_between(x, y_est - y_err, y_est + y_err, alpha=0.2)\n",
    "    axes.set_ylabel('Average Distance')\n",
    "    axes.set_xlabel('Month')\n",
    "    axes.set_title(\"Average Distance per Month\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_avg_distance_month():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_avg_distance_month()\n",
    "plot_avg_distance_month(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "275a1af2",
   "metadata": {},
   "source": [
    "### Visualization 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e60fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dropoffs_ny_area(dataframe: pd.DataFrame):\n",
    "\n",
    "    days = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "\n",
    "    lga = [4, 5, 1, 8, 3, 9, 2]\n",
    "    jfk = [9, 2, 8, 4, 5, 8, 1]\n",
    "    ewr = [9, 7, 3, 7, 2, 9, 4]\n",
    "\n",
    "    x_axis = np.arange(len(days))\n",
    "  \n",
    "    plt.bar(x_axis - 0.2, lga, 0.4, label = 'LGA')\n",
    "    plt.bar(x_axis + 0.2, jfk, 0.4, label = 'JFK')\n",
    "    plt.bar(x_axis + 0.4, ewr, 0.4, label = 'EWR')\n",
    "\n",
    "    plt.xlabel(\"Days in Week\")\n",
    "    plt.ylabel(\"Drop Offs\")\n",
    "    plt.title(\"Drop-Offs per Airport\")\n",
    "\n",
    "    plt.xticks(x_axis, days)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dropoffs_ny_area():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_dropoffs_ny_area()\n",
    "plot_dropoffs_ny_area(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e085f33",
   "metadata": {},
   "source": [
    "### Visualization 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trips_area(dataframe: pd.DataFrame):    \n",
    "    map_obj = folium.Map(location = [40.730610, -73.935242], zoom_start = 10, min_zoom = 10, tiles='CartoDB positron')\n",
    "\n",
    "    lats_longs = [\n",
    "                    [40.7554, -73.9862],\n",
    "                    [40.7794, -73.9654],\n",
    "                    [40.7223, -73.9982],\n",
    "                    [40.7455, -74.0071],\n",
    "                ]\n",
    "\n",
    "    HeatMap(lats_longs).add_to(map_obj)\n",
    "    return map_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_trips_area():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_trips_area()\n",
    "plot_trips_area(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9029b60",
   "metadata": {},
   "source": [
    "### Visualization 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "acdcd1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tips_distance(dataframe: pd.DataFrame):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    tips = [2, 6, 3, 7, 8, 1, 9, 22, 9, 6, 22, 1]\n",
    "    distance = [1, 5, 3, 2, 5, 7, 8, 1, 9, 23, 6, 7]\n",
    "\n",
    "    axes.scatter(distance, tips, marker='o', alpha=0.5)\n",
    "    axes.set_title(\"Yellow Tips - Tips vs. Distance\")\n",
    "    axes.set_ylabel('Popularity')\n",
    "    axes.set_xlabel('Distance')\n",
    "    axes.set_xlim(-1, 11)\n",
    "    axes.set_ylim(-1, 10)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tips_distance():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_tips_distance()\n",
    "plot_tips_distance(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "410cfcdd",
   "metadata": {},
   "source": [
    "### Visualization 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd37fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "17fa4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tips_precipitation(dataframe: pd.DataFrame):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    tips = [2, 6, 3, 7, 8, 1, 9, 22, 9, 6, 22, 1]\n",
    "    precipication = [1, 5, 3, 2, 5, 7, 8, 1, 9, 23, 6, 7]\n",
    "\n",
    "    ## Animation\n",
    "\n",
    "    frames = 10\n",
    "    points = len(tips)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    sizes = itertools.cycle([10, 50, 150])\n",
    "    colors = np.random.rand(frames, points)\n",
    "    colormaps = itertools.cycle(['Purples', 'Blues', 'Greens', 'Oranges', 'Reds'])\n",
    "    markers = itertools.cycle(['o', 'v', '^', 's', 'p'])\n",
    "\n",
    "    def update(i):\n",
    "        axes.clear()\n",
    "\n",
    "        axes.scatter(precipication, tips,\n",
    "                s=next(sizes),\n",
    "                c=colors[i, :],\n",
    "                cmap=next(colormaps),\n",
    "                marker=next(markers),\n",
    "                alpha=0.5)\n",
    "\n",
    "        axes.set_title(\"Yellow Taxi - Tips vs. Precipitation\")\n",
    "        axes.set_ylabel('Precipitation')\n",
    "        axes.set_xlabel('Tips')\n",
    "        axes.set_xlim(-1, 11)\n",
    "        axes.set_ylim(-1, 10)\n",
    "\n",
    "    anim = animation.FuncAnimation(figure, update, frames=frames, interval=500)\n",
    "    anim\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tips_precipitation():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_tips_precipitation()\n",
    "plot_tips_precipitation(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d659ea492a6423f437f8c825d2ef59ba06a7f23250fb4bfa35b0a006bd446c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
