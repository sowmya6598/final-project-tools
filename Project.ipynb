{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32f8ca24",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1uAUJGEUzfNj6OsWNAimnYCw7eKaHhMUfU1MTj9YwYw4/edit?usp=sharing), [grading rubric](https://docs.google.com/document/d/1hKuRWqFcIdhOkow3Nljcm7PXzIkoa9c_aHkMKZDxWa0/edit?usp=sharing)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only an outline to help you with your own approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f75fd94",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "66dcde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "import math\n",
    "import os\n",
    "import bs4\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import pyarrow.parquet as pq\n",
    "import matplotlib.animation as animation\n",
    "import pandas as pd\n",
    "import requests\n",
    "import itertools\n",
    "import sqlalchemy as db\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from geopy.distance import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "3f1242c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"any constants you might need; some have been added for you, and some you need to fill in\"\"\"\n",
    "\n",
    "TAXI_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"data/taxi_zones\"\n",
    "TAXI_ZONES_SHAPEFILE = \"taxi_zones.shp\"\n",
    "UBER_CSV = \"\"\n",
    "WEATHER_CSV_DIR = \"\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "d6601633",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Make sure the QUERY_DIRECTORY exists\"\"\"\n",
    "try:\n",
    "    os.mkdir(QUERY_DIRECTORY)\n",
    "except Exception as e:\n",
    "    if e.errno == 17:\n",
    "        # the directory already exists\n",
    "        pass\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad10ea",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d53e24",
   "metadata": {},
   "source": [
    "### Load Taxi Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "58708809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function takes the shapefile and returns an object\n",
    "    consisting of each zone, locationId and its geomtry coordinates \"\"\"\n",
    "\n",
    "def load_taxi_zones(shapefile: str) -> dict:\n",
    "    gdf = gpd.read_file(shapefile)\n",
    "\n",
    "    taxi_zones = []\n",
    "\n",
    "    for index, row in gdf.iterrows():\n",
    "        zone = row.iloc[3]\n",
    "        locationId = row.iloc[4]\n",
    "        geometry = row.iloc[6]\n",
    "        \n",
    "        row_object = { \"zone\": zone, \"locationId\": locationId, \"geometry\": geometry }\n",
    "        taxi_zones.append(row_object)\n",
    "    \n",
    "    return taxi_zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "50421a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_data = load_taxi_zones(TAXI_ZONES_SHAPEFILE)\n",
    "# There are 263 location Ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "8d04c726",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function accepts the zone id and the taxi zones\n",
    "    and matches the zone id with its relevant coordinates \"\"\"\n",
    "\n",
    "def lookup_coords_for_taxi_zone_id(zone_loc_id: int, loaded_taxi_zones: list) -> int:\n",
    "    for i in loaded_taxi_zones:\n",
    "        if i['locationId'] == zone_loc_id:\n",
    "            return i['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "14b73fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263]\n"
     ]
    }
   ],
   "source": [
    "cord = []\n",
    "for x in range(1,264): \n",
    "    cord.append(x)\n",
    "\n",
    "poly = []\n",
    "for x in cord:\n",
    "    poly.append(lookup_coords_for_taxi_zone_id(x, shape_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "06e20a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(40.69183016020959, -74.17400156582248),\n",
       " (40.61674619937379, -73.83129979354713),\n",
       " (40.86447372906584, -73.8474217852696),\n",
       " (40.72375208451233, -73.97696827424141),\n",
       " (40.55265878064343, -74.18848459794721),\n",
       " (40.600324409468406, -74.07177024696533),\n",
       " (40.761492617043125, -73.91969433569462),\n",
       " (40.77855862576789, -73.92308626324494),\n",
       " (40.75103435668664, -73.78794875477833),\n",
       " (40.67895308442328, -73.79098676199028),\n",
       " (40.60427268170344, -74.00748784386448),\n",
       " (40.70294582144012, -74.01556349991374),\n",
       " (40.712037924667264, -74.01607927269924),\n",
       " (40.62483367229869, -74.0298925099),\n",
       " (40.7833330046879, -73.78597285841018),\n",
       " (40.76273753216493, -73.77342112932584),\n",
       " (40.69150702161197, -73.94990480444068),\n",
       " (40.86768222238494, -73.89018381164814),\n",
       " (40.73548651046706, -73.72665540152784),\n",
       " (40.857779440562844, -73.88586744911127),\n",
       " (40.60142907301775, -73.98353783537917),\n",
       " (40.61221766982795, -73.99525864587314),\n",
       " (40.60644824321443, -74.17088508711593),\n",
       " (40.80197051563418, -73.96547935663406),\n",
       " (40.68563370139058, -73.98611374739605),\n",
       " (40.630949253264255, -73.98866057160336),\n",
       " (40.559134755628214, -73.90691199328067),\n",
       " (40.71159648931973, -73.80872922918115),\n",
       " (40.580921751571346, -73.96121662082737),\n",
       " (40.60368693988757, -73.82192752206782),\n",
       " (40.85774566451417, -73.87547602176667),\n",
       " (40.86400203645644, -73.86490091353166),\n",
       " (40.6957980847225, -73.99525009947318),\n",
       " (40.70085574405344, -73.97118860464191),\n",
       " (40.664002936640344, -73.91025776959916),\n",
       " (40.700522076773844, -73.91770956300488),\n",
       " (40.69499398960586, -73.92223688327465),\n",
       " (40.69434123971375, -73.73555411751046),\n",
       " (40.63803689672939, -73.8997346848635),\n",
       " (40.67919897887253, -73.99595622535054),\n",
       " (40.804333857858566, -73.95129204385638),\n",
       " (40.8182572500734, -73.94077208625764),\n",
       " (40.78247701262984, -73.96555540550199),\n",
       " (40.52549110546785, -74.23353546082052),\n",
       " (40.712459285136994, -73.99815145865519),\n",
       " (40.84908569070797, -73.78198762631824),\n",
       " (40.84274838600792, -73.90031694602852),\n",
       " (40.76225259858687, -73.98984489812494),\n",
       " (40.687967206026975, -73.96236337094902),\n",
       " (40.76623762332451, -73.99513534858681),\n",
       " (40.87397243195906, -73.82826339600581),\n",
       " (40.6866511779156, -73.99672407074303),\n",
       " (40.780911658515755, -73.84281297899702),\n",
       " (40.68720061705318, -74.00291135102258),\n",
       " (40.576961310705336, -73.98794360684474),\n",
       " (40.741406719488175, -73.85884527575628),\n",
       " (None, None),\n",
       " (40.84145193921358, -73.8203932847595),\n",
       " (40.83855027505839, -73.89498592772226),\n",
       " (40.83399041103506, -73.88590027069773),\n",
       " (40.674469714192334, -73.93928693565553),\n",
       " (40.666540670529315, -73.94878830363868),\n",
       " (40.68383988904548, -73.87817285854474),\n",
       " (40.760614500455986, -73.73933650195845),\n",
       " (40.69533747220738, -73.98608592282788),\n",
       " (40.70225894512564, -73.98570157061832),\n",
       " (40.6196189778478, -74.01380228070624),\n",
       " (40.7484273300986, -73.99991779023728),\n",
       " (40.83141625187568, -73.91503006977001),\n",
       " (40.76335208099607, -73.86839538867875),\n",
       " (40.6442876673477, -73.93796619973367),\n",
       " (40.652364445415, -73.92225101477305),\n",
       " (40.75410890581649, -73.80729410936029),\n",
       " (40.80116912880846, -73.9373456595586),\n",
       " (40.79001067629398, -73.94575022751276),\n",
       " (40.660934157913516, -73.87682021500527),\n",
       " (40.66655871582285, -73.89536390861545),\n",
       " (40.84496040702046, -73.88552154399945),\n",
       " (40.727620122038296, -73.98593745737395),\n",
       " (40.71536964922733, -73.9367935879161),\n",
       " (40.880935114970065, -73.83664438963196),\n",
       " (40.73949534354323, -73.8771183310234),\n",
       " (40.73832393052052, -73.89217342295797),\n",
       " (40.528685582160755, -74.18767927741463),\n",
       " (40.64611615465671, -73.95162326816249),\n",
       " (40.60243266654381, -73.75524330826842),\n",
       " (40.706808425516016, -74.00749595416085),\n",
       " (40.70335788054845, -74.0115150281245),\n",
       " (40.63789963509721, -73.96096805763649),\n",
       " (40.742278583312206, -73.99697147759031),\n",
       " (40.62627246088452, -73.93009718315575),\n",
       " (40.7611014398131, -73.82885854846761),\n",
       " (40.74067383007372, -73.84086521275654),\n",
       " (40.858155189262895, -73.89953594476775),\n",
       " (40.72143156737173, -73.84766908657137),\n",
       " (40.697001507866105, -73.8715612898338),\n",
       " (40.690786583767746, -73.9748820144768),\n",
       " (40.73446263709748, -73.77725343413134),\n",
       " (40.57677255023222, -74.18642081572338),\n",
       " (40.75351274051303, -73.98878660966813),\n",
       " (40.74599312386359, -73.7110254285456),\n",
       " (40.7035460869547, -73.87573702732386),\n",
       " (40.68986010346147, -74.04528828347375),\n",
       " (None, None),\n",
       " (None, None),\n",
       " (40.67351267831398, -73.99064755008082),\n",
       " (40.73682398302768, -73.98405214924436),\n",
       " (40.58840360836442, -73.9814314279712),\n",
       " (40.55186202510041, -74.15089028926955),\n",
       " (40.54577972821088, -74.12834311100727),\n",
       " (40.65213720698318, -73.9902343725197),\n",
       " (40.72950616875672, -73.94954001249944),\n",
       " (40.732579026253674, -73.9943047162786),\n",
       " (40.72834036831643, -73.9973801630823),\n",
       " (40.61797101224406, -74.0878388464394),\n",
       " (40.82701260635661, -73.94852183123933),\n",
       " (40.59405915427385, -73.78962334973271),\n",
       " (40.58655482658562, -74.13298451453818),\n",
       " (40.837826783716714, -73.92615757846964),\n",
       " (40.8466669452917, -73.9301832301702),\n",
       " (40.72833291964906, -73.80244388409426),\n",
       " (40.71063914369108, -73.76113689765596),\n",
       " (40.59995386265359, -73.96433354731992),\n",
       " (40.6582475138648, -73.8449181204672),\n",
       " (40.72629040399525, -74.0074858070925),\n",
       " (40.81207420841891, -73.8855370337455),\n",
       " (40.866074893138844, -73.9193084235328),\n",
       " (40.872378832666904, -73.92436989163414),\n",
       " (40.75731177578825, -73.88531729044865),\n",
       " (40.70436904839545, -73.79398113023713),\n",
       " (40.72065547306544, -73.77610108565929),\n",
       " (40.64698510024821, -73.78652986349012),\n",
       " (40.640589941044496, -73.97619875860275),\n",
       " (40.70805097274517, -73.82871239790782),\n",
       " (40.72837725250497, -73.82119497835454),\n",
       " (40.86526406538748, -73.90591127838628),\n",
       " (40.74043892115907, -73.97649469938301),\n",
       " (40.774375816732636, -73.873628438902),\n",
       " (40.67709753140416, -73.7442347963469),\n",
       " (40.76548395144242, -73.9547390603464),\n",
       " (40.76694805479654, -73.95963501136171),\n",
       " (40.773633196128905, -73.98153235360773),\n",
       " (40.77596514731965, -73.9876456908124),\n",
       " (40.72088884086805, -73.99691858884708),\n",
       " (40.74537934472369, -73.94889156149159),\n",
       " (40.75424253686729, -73.93482891700025),\n",
       " (40.81967568059164, -73.89895654395085),\n",
       " (40.718938301131104, -73.99089636602756),\n",
       " (40.6049134658026, -73.94813561950728),\n",
       " (40.58047335130059, -73.94362868028261),\n",
       " (40.79796198028393, -73.96816820440951),\n",
       " (40.81797510016547, -73.95378220824486),\n",
       " (40.875967791801536, -73.91037864632285),\n",
       " (40.59357106687244, -73.90259516689072),\n",
       " (40.61459130879868, -73.91527729481503),\n",
       " (40.63130767438205, -74.16723425044069),\n",
       " (40.72399485039648, -73.90233075376986),\n",
       " (40.7350351831651, -74.00898419902498),\n",
       " (40.81825981956973, -73.91284931725946),\n",
       " (40.71833678461975, -73.88005123769709),\n",
       " (40.758027981780664, -73.97769803041939),\n",
       " (40.756687537617346, -73.97235615813489),\n",
       " (40.7644214387746, -73.97756856896713),\n",
       " (40.74857453693654, -73.98515644835915),\n",
       " (40.62092382865375, -73.95682439069601),\n",
       " (40.80945681703888, -73.96176369363279),\n",
       " (40.82751259617852, -73.90235207986518),\n",
       " (40.80734711638027, -73.91682152685682),\n",
       " (40.849058285066626, -73.90512246226346),\n",
       " (40.74774573203895, -73.97849158432054),\n",
       " (40.76835161995764, -73.80954532050765),\n",
       " (40.57176876885639, -74.10501884907058),\n",
       " (40.75257918636062, -73.86303757637424),\n",
       " (40.87713740796544, -73.87902219325525),\n",
       " (40.74267113545859, -73.75462177515529),\n",
       " (40.56199406259296, -74.12258304710812),\n",
       " (40.676643979648, -73.91363232497895),\n",
       " (40.617314684335554, -73.97032564615044),\n",
       " (40.77157021384615, -73.92833298669993),\n",
       " (40.675595010201214, -73.84704288454616),\n",
       " (40.670373980768005, -73.98141430754676),\n",
       " (40.837748625040106, -73.85798693850145),\n",
       " (40.849172484756885, -73.83158183808297),\n",
       " (40.86827511264962, -73.80785826289252),\n",
       " (40.8544049401438, -73.85439389980314),\n",
       " (40.74849716576957, -73.99243754419264),\n",
       " (40.62816593004213, -74.14078866147455),\n",
       " (40.65874469984108, -73.94744186388097),\n",
       " (40.67763534192634, -73.96758665136912),\n",
       " (40.661621710598034, -73.9689138001589),\n",
       " (40.71545380257635, -73.74153154913715),\n",
       " (40.74375187633024, -73.81522924223742),\n",
       " (40.76031345682181, -73.941997345654),\n",
       " (40.79100048638123, -73.92459671825748),\n",
       " (40.675548647019355, -74.00917842826674),\n",
       " (40.72615524559957, -73.86333836633429),\n",
       " (40.6945423878432, -73.83092432071815),\n",
       " (40.70652682085338, -73.9017091770337),\n",
       " (40.791132912174135, -73.88265799878711),\n",
       " (40.89952838046226, -73.90698753009411),\n",
       " (40.57798298905335, -73.84345437593673),\n",
       " (40.761899335777855, -73.94995272044949),\n",
       " (40.6578524002613, -73.73947394708196),\n",
       " (40.540333107919224, -74.20782577848769),\n",
       " (40.69120081596648, -73.76314608999355),\n",
       " (40.6389731051429, -74.10231443709439),\n",
       " (40.76398556081556, -73.89935257380462),\n",
       " (40.82331779920538, -73.82353890836147),\n",
       " (40.70907271927832, -74.00366448904686),\n",
       " (40.59202360691843, -73.94050725344536),\n",
       " (40.723888072060404, -74.00153759512791),\n",
       " (40.82790234607947, -73.86967998064887),\n",
       " (40.817858732890684, -73.8581349352209),\n",
       " (40.586786351126605, -74.08551242969601),\n",
       " (40.69442751519797, -73.79096478957263),\n",
       " (40.67615367273836, -73.8194594633455),\n",
       " (40.70391646835313, -73.95859683039497),\n",
       " (40.67208987326582, -73.77303557005415),\n",
       " (40.6621855181538, -73.7645050464996),\n",
       " (40.882403144304526, -73.91066491034807),\n",
       " (40.61876814401099, -74.07370335971028),\n",
       " (40.64752693460751, -73.88241274352464),\n",
       " (40.77742668296697, -73.9054073938334),\n",
       " (40.73182059189006, -73.97659759721292),\n",
       " (40.68816808255134, -73.93188776883784),\n",
       " (40.73769793411764, -73.92467277449282),\n",
       " (40.64188612045834, -74.00465260064145),\n",
       " (40.65235415076564, -74.0112729089247),\n",
       " (40.75672890813223, -73.96514581878095),\n",
       " (40.759817566309465, -73.98419655675737),\n",
       " (40.71777262479923, -74.0078796687525),\n",
       " (40.71473247007343, -73.98302469110321),\n",
       " (40.74991400028384, -73.97044261148469),\n",
       " (40.74033737258096, -73.9904579133977),\n",
       " (40.85252096967172, -73.91597580806709),\n",
       " (40.78043629001211, -73.95701192571859),\n",
       " (40.76861505664575, -73.96563472764679),\n",
       " (40.79170489453925, -73.9730488247599),\n",
       " (40.78396140232239, -73.97863191501314),\n",
       " (40.89459870941774, -73.88197740171728),\n",
       " (40.876512149833516, -73.89562019423215),\n",
       " (40.846783165013896, -73.85067120117776),\n",
       " (40.857108002782724, -73.93283170504228),\n",
       " (40.84170843286747, -73.94139929841424),\n",
       " (40.630049214870475, -74.10286021352394),\n",
       " (40.75330875946255, -74.00401551098165),\n",
       " (40.82898744957318, -73.9244099256833),\n",
       " (40.834165310932306, -73.87228957125745),\n",
       " (40.73457589628757, -74.00287502314927),\n",
       " (40.83210137235689, -73.84864087551631),\n",
       " (40.61688017760985, -74.12534780784381),\n",
       " (40.78819313151885, -73.81565687221273),\n",
       " (40.76063069299949, -73.84124397042739),\n",
       " (40.882156652347604, -73.85894862514452),\n",
       " (40.71880389196212, -73.95741813772918),\n",
       " (40.710880017563596, -73.95990457422253),\n",
       " (40.65361164157177, -73.97798212852373),\n",
       " (40.68872119747495, -73.85576671853391),\n",
       " (40.89793210648794, -73.85221512421664),\n",
       " (40.74423361478699, -73.90630719190789),\n",
       " (40.709138876288186, -74.01302283778836),\n",
       " (40.77593230221761, -73.94651047848446),\n",
       " (40.77876573980772, -73.9510100659439)]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyproj\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Define the CRS of your input coordinates\n",
    "input_crs = 'EPSG:2263'\n",
    "\n",
    "# Define the CRS to which you want to convert your coordinates\n",
    "output_crs = 'EPSG:4326'\n",
    "\n",
    "# Create a PyProj transformer object to convert between the two CRSs\n",
    "transformer = pyproj.Transformer.from_crs(input_crs, output_crs)\n",
    "l = []\n",
    "for i in range(len(poly)):\n",
    "    if i == 56 or i == 103 or i == 104:\n",
    "        l.append((None,None))\n",
    "    else:\n",
    "        centroid2 = Point(poly[i].centroid.x, poly[i].centroid.y)\n",
    "        centroid_wgs84 = transformer.transform(centroid2.x, centroid2.y)\n",
    "        l.append(centroid_wgs84)\n",
    "\n",
    "my_dict = {index: item for index, item in enumerate(l, start=1)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca606b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test - lookup_coords_for_taxi_zone_id() \"\"\"\n",
    "\n",
    "def lookup_coords_for_taxi_zone_id_test():\n",
    "\n",
    "    zones = [{ \"zone\": 3, \"locationId\": 1, \"geometry\": 5 }, { \"zone\": 8, \"locationId\": 7, \"geometry\": 3 }]\n",
    "    assert lookup_coords_for_taxi_zone_id(1, zones)  == 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32074561",
   "metadata": {},
   "source": [
    "### Calculate distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4cbbe6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function calculate the distance giving the pick up\n",
    "    point and drop off point and returns a distance integer \"\"\"\n",
    "\n",
    "def calculate_distance_with_coords(from_coord: tuple, to_coord: tuple) -> int:\n",
    "    pickup_latitude, pickup_longitude = from_coord\n",
    "    dropoff_latitude, dropoff_longitude = to_coord\n",
    "\n",
    "    coords = [pickup_latitude, dropoff_latitude, pickup_longitude, dropoff_longitude]\n",
    "\n",
    "    for i in coords:\n",
    "        if i < -90 or i > 90:\n",
    "            return -1\n",
    "\n",
    "    return distance((pickup_latitude, pickup_longitude), (dropoff_latitude, dropoff_longitude)).miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "d3c5faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test - calculate_distance_with_coords() \"\"\"\n",
    "\n",
    "def calculate_distance_with_coords_test():\n",
    "\n",
    "    from_coord = (37.7749, -12.4194)\n",
    "    to_coord = (34.0522, -11.2437)\n",
    "    assert round(calculate_distance_with_coords(from_coord, to_coord), 2) == 264.99\n",
    "\n",
    "\n",
    "    from_coord = (105, -122.4194)\n",
    "    to_coord = (34.0522, -118.2437) \n",
    "    assert calculate_distance_with_coords(from_coord, to_coord) == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "6d6abf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function adds a new column with the distance between coordinates to the Dataframe.\n",
    "    The input is a dataframe and the output is the new dataframe \"\"\"\n",
    " \n",
    "def add_distance_column(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Apply the calculate_distance_with_coords function to each row of the DataFrame\n",
    "    distances = dataframe.apply(lambda row: calculate_distance_with_coords(\n",
    "        (row[\"pickup_latitude\"], row[\"pickup_longitude\"]),\n",
    "        (row[\"dropoff_latitude\"], row[\"dropoff_longitude\"])\n",
    "    ), axis=1)\n",
    "    \n",
    "    # Add the distances as a new column to the DataFrame\n",
    "    dataframe[\"distance\"] = distances\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "912a73d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test - add_distance_column() \"\"\"\n",
    "\n",
    "def add_distance_column_test():\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'pickup_latitude': [40.7128],\n",
    "        'pickup_longitude': [-74.006],\n",
    "        'dropoff_latitude': [40.7851],\n",
    "        'dropoff_longitude': [-73.9683]\n",
    "    })\n",
    "\n",
    "    df_with_distance = add_distance_column(df)\n",
    "\n",
    "    assert \"distance\" in df_with_distance.columns, 'distance column is not present'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daa717",
   "metadata": {},
   "source": [
    "### Process Taxi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function downloads all the relevant files from the taxi webpage\n",
    "    and places it into our local directory \"\"\"\n",
    "\n",
    "def download_files(month: int, year: int):\n",
    "    formatted_month = f\"{month:02d}\"\n",
    "    current_dir = os.getcwd()\n",
    "    url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{formatted_month}.parquet\"\n",
    "    \n",
    "    windows = f\"{current_dir}\\\\\"\n",
    "    str = windows if  os.name == 'nt' else \"\"\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(f\"{str}yellow_taxi_{year}_{formatted_month}.parquet\", \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=1024): \n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "years = list(range(2009, 2016))\n",
    "months = list(range(1, 13))\n",
    "\n",
    "for year in years:\n",
    "    if year < 2015:\n",
    "        for month in months:\n",
    "            download_files(month, year)\n",
    "    else:\n",
    "        for month in range(1, 7):\n",
    "            download_files(month, year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "1dd682b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function gets all the URLs from the taxi web page and returns\n",
    "    it as an array of strings \"\"\"\n",
    "\n",
    "def get_all_urls_from_taxi_page(taxi_page: str) -> list[str]:\n",
    "    try:\n",
    "        response = requests.get(taxi_page)\n",
    "\n",
    "        soup = bs4.BeautifulSoup(response.content, 'html.parser')\n",
    "        urls = []\n",
    "\n",
    "        for link in soup.find_all('a'):\n",
    "            href = link.get('href')\n",
    "            if href is not None:\n",
    "                urls.append(href)\n",
    "\n",
    "        return urls\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "9a7813aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\" test for get_all_urls_from_taxi_page() \"\"\"\n",
    "\n",
    "def get_all_urls_from_taxi_page_test():\n",
    "\n",
    "    assert len(get_all_urls_from_taxi_page(TAXI_URL)) == 483"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "cbd0d198",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function goes through all the URLs on the taxi web page\n",
    "    and returns only the ones ending in .parquet since we want\n",
    "    parquet files and also the ones from the years 2009 to 2015\n",
    "    to avoid iterating through unecessary files. \"\"\"\n",
    "\n",
    "def filter_taxi_parquet_urls(all_urls: list[str]) -> list[str]:\n",
    "    parquet_urls = []\n",
    "    years = list(range(2009, 2016))\n",
    "\n",
    "    if all_urls is not None:\n",
    "        for i in all_urls:\n",
    "            str = re.search('.parquet$', i)\n",
    "\n",
    "            if(str != None and \"yellow_tripdata\" in i):\n",
    "                year = int(i.split(\"_\")[2][:4])\n",
    "\n",
    "                if year in years:\n",
    "                    parquet_urls.append(i)\n",
    "    return parquet_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "08f83106",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test for filter_taxi_parquet_urls() \"\"\"\n",
    "\n",
    "def filter_taxi_parquet_urls_test():\n",
    "\n",
    "    allUrlsData = get_all_urls_from_taxi_page(TAXI_URL)\n",
    "    assert len(filter_taxi_parquet_urls(allUrlsData)) == 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "2f40130a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function takes a URL and extracts the month from it\n",
    "    The example url can look like:\n",
    "    https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet \"\"\"\n",
    "\n",
    "def get_and_clean_month(url: str) -> str:\n",
    "    str = url[len(url) - 10:]\n",
    "    [month, fileType] = str.split('.')\n",
    "    return month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "15238bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test for get_and_clean_month function \"\"\"\n",
    "\n",
    "def get_and_clean_month_test():\n",
    "\n",
    "    url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet'\n",
    "    assert get_and_clean_month(url) == '06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "f15da82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function takes a URL and extracts the year from it\n",
    "    The example url can look like:\n",
    "    https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet \"\"\"\n",
    "\n",
    "def get_and_clean_year(url: str) -> str:\n",
    "    str = url[len(url) - 15:]\n",
    "    [year, other] = str.split('-')\n",
    "    return year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "9aee9f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test for get_and_clean_year function \"\"\"\n",
    "\n",
    "def get_and_clean_year_test():\n",
    "\n",
    "    url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2022-06.parquet'\n",
    "    assert get_and_clean_year(url) == '2022'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "cd58b896",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This fucntion adds a new column with the distance between coordinates to the taxi Dataframe.\n",
    "    The input is a dataframe and the output is the new modified dataframe \"\"\"\n",
    " \n",
    "def add_distance_column_taxi(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Apply the calculate_distance_with_coords function to each row of the DataFrame\n",
    "    distances = dataframe.apply(lambda row: calculate_distance_with_coords(\n",
    "        (row[\"Start_Lat\"], row[\"Start_Lon\"]),\n",
    "        (row[\"End_Lat\"], row[\"End_Lon\"])\n",
    "    ), axis=1)\n",
    "    \n",
    "    # Add the distances as a new column to the DataFrame\n",
    "    dataframe[\"distance\"] = distances\n",
    "    \n",
    "    return dataframe[\"distance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "82888d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" test - add_distance_column_taxi() \"\"\"\n",
    "\n",
    "def add_distance_column_taxi_test():\n",
    "\n",
    "    df_taxi = pd.DataFrame({\n",
    "        'Start_Lat': [40.7128],\n",
    "        'Start_Lon': [-74.006],\n",
    "        'End_Lat': [40.7851],\n",
    "        'End_Lon': [-73.9683]\n",
    "    })\n",
    "\n",
    "    df_taxi_with_distance = add_distance_column_taxi(df_taxi)\n",
    "\n",
    "    assert df_taxi_with_distance.shape[0] == 1\n",
    "    assert isinstance(df_taxi_with_distance, pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "35c9c0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function collects all the parquet urls from the taxi website.\n",
    "    It will then get the actual data from the parquet files and do various forms of cleaning.\n",
    "    For example, we will remove unnecessary columns and invalid data and will return\n",
    "    one gigantic dataframe with data from every month \"\"\"\n",
    "\n",
    "def convert_taxi_data(parquet_urls: list[str]) -> pd.DataFrame:\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    for parquet_url in parquet_urls:\n",
    "        month = get_and_clean_month(parquet_url)\n",
    "        year = get_and_clean_year(parquet_url)\n",
    "\n",
    "        cwd = os.getcwd()\n",
    "        files = os.listdir(cwd)\n",
    "\n",
    "        fileName = f\"yellow_taxi_{year}_{month}.parquet\"\n",
    "        if fileName in files :\n",
    "\n",
    "            dataframe = pd.read_parquet(fileName)\n",
    "            sample_dataframe = dataframe.sample(n=3000)\n",
    "            all_taxi_dataframes.append(sample_dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "200776ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This function gets all the urls from the taxi page, specifically the parquet urls,\n",
    "    gets and cleans it, and returns the valid data \"\"\"\n",
    "\n",
    "def get_taxi_data() -> pd.DataFrame:\n",
    "    all_urls = get_all_urls_from_taxi_page(TAXI_URL)\n",
    "    all_parquet_urls = filter_taxi_parquet_urls(all_urls)\n",
    "    taxi_data = convert_taxi_data(all_parquet_urls)\n",
    "\n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "ac161e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This fucntion selects only the needed columns and dropps the rest. It also combines some columns as the data is spread across mutltiple\n",
    "\"\"\"\n",
    "\n",
    "def set_up_taxi_dataset() -> pd.DataFrame:\n",
    "\n",
    "    selected_cols = ['tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance','PULocationID', 'DOLocationID','fare_amount','tip_amount','total_amount','pickup_datetime', 'dropoff_datetime', 'pickup_longitude', 'pickup_latitude',  'dropoff_longitude', 'dropoff_latitude', 'Trip_Pickup_DateTime', 'Trip_Dropoff_DateTime', 'Passenger_Count', 'Trip_Distance', 'Start_Lon', 'Start_Lat',  'End_Lon', 'End_Lat',  'Fare_Amt', 'Tip_Amt', 'Total_Amt']\n",
    "    df_selected = get_taxi_data()\n",
    "    df_selected = df_selected[selected_cols]\n",
    "    # list of column pairs to join\n",
    "    column_pairs = [(\"tpep_pickup_datetime\", 'pickup_datetime'), \n",
    "                    (\"tpep_dropoff_datetime\", 'dropoff_datetime'),\n",
    "                    ('Trip_Distance', 'trip_distance'),\n",
    "                    ('Passenger_Count', 'passenger_count'),\n",
    "                    ('Start_Lon', 'PULocationID'),\n",
    "                    ('Start_Lat', 'PULocationID'),\n",
    "                    ('End_Lon', 'DOLocationID'),\n",
    "                    ('End_Lat', 'DOLocationID'),\n",
    "                    ('Fare_Amt', 'fare_amount'),\n",
    "                    ('Tip_Amt', 'tip_amount'),\n",
    "                    ('Total_Amt', 'total_amount')]\n",
    "\n",
    "    # loop over column pairs and join them\n",
    "    for pair in column_pairs:\n",
    "        # fill missing values in the first column with values from the second column\n",
    "        df_selected[pair[0]] = df_selected[pair[0]].fillna(df_selected[pair[1]])\n",
    "        # drop the second column\n",
    "        df_selected_final = df_selected.drop(pair[1], axis=1)\n",
    "\n",
    "    df_selected_final = df_selected_final.drop(['pickup_datetime',\t'dropoff_datetime', 'passenger_count', 'trip_distance', 'PULocationID', 'DOLocationID', 'fare_amount', 'tip_amount', 'pickup_longitude',\t'pickup_latitude',\t'dropoff_longitude'\t,'dropoff_latitude'], axis=1)\n",
    "\n",
    "\n",
    "    column_pairs = [(\"tpep_pickup_datetime\", 'Trip_Pickup_DateTime'), \n",
    "                    (\"tpep_dropoff_datetime\", 'Trip_Dropoff_DateTime')]\n",
    "\n",
    "\n",
    "    # loop over column pairs and join them\n",
    "    for pair in column_pairs:\n",
    "        # fill missing values in the first column with values from the second column\n",
    "        df_selected_final[pair[0]] = df_selected_final[pair[0]].fillna(df_selected_final[pair[1]])\n",
    "        # drop the second column\n",
    "        df_selected_final = df_selected_final.drop(pair[1], axis=1)\n",
    "\n",
    "        return df_selected_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "09195fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF= set_up_taxi_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "e1411320",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = DF.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "2c64f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that performs the lookup operation\n",
    "def lookup_lat(x):\n",
    "    result = my_dict.get(x)\n",
    "    if result is not None:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "# define a function that performs the lookup operation\n",
    "def lookup_lon(x):\n",
    "    result = my_dict.get(x)\n",
    "    if result is not None:\n",
    "        return result[1]\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "fbb213c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the lookup function to all the columns in the DataFrame\n",
    "#%time\n",
    "df2[\"End_Lon\"] = df2[\"End_Lon\"].apply(lambda x: lookup_lon(x))\n",
    "df2[\"Start_Lon\"] = df2[\"Start_Lon\"].apply(lambda x: lookup_lon(x))\n",
    "\n",
    "df2[\"Start_Lat\"] = df2[\"Start_Lat\"].apply(lambda x: lookup_lat(x))\n",
    "df2[\"End_Lat\"] = df2[\"End_Lat\"].apply(lambda x: lookup_lat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "486a8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "We then filter based on coordinates to make sure the rides are within the coordinates we want.\n",
    "We also remove trips with 0 passangers and no fares. We further remove trips with passangers above 6 as that \n",
    "is uber policy. Lastly we remove trips with no distace between dropoff and pickup. The output is the\n",
    "cleaned dataframe\n",
    "'''\n",
    "def filter_taxi_data() -> pd.DataFrame:\n",
    "\n",
    "    df_selected_final = df2\n",
    "    df_selected_final = df_selected_final[(df_selected_final[\"Start_Lat\"] >= 40.560445) & \n",
    "                                        (df_selected_final[\"Start_Lon\"] >= -74.242330) & \n",
    "                                        (df_selected_final[\"Start_Lat\"] <= 40.908524) & \n",
    "                                        (df_selected_final[\"Start_Lon\"] <= -73.717047) &\n",
    "                                        (df_selected_final[\"End_Lat\"] >= 40.560445) & \n",
    "                                        (df_selected_final[\"End_Lon\"] >= -74.242330) & \n",
    "                                        (df_selected_final[\"End_Lat\"] <= 40.908524) & \n",
    "                                        (df_selected_final[\"End_Lon\"] <= -73.717047)]\n",
    "\n",
    "\n",
    "    df_selected_final = df_selected_final[df_selected_final['Passenger_Count'] != 0]\n",
    "\n",
    "    add_distance_column_taxi(df_selected_final)\n",
    "\n",
    "    df_selected_final = df_selected_final.drop(index=df_selected_final[df_selected_final['distance'] == 0].index)\n",
    "\n",
    "    df_selected_final = df_selected_final[df_selected_final['Passenger_Count']<=6.0]\n",
    "    df_selected_final = df_selected_final.reset_index(drop=True)\n",
    "    df_selected_final = df_selected_final.rename(columns={\n",
    "        \"tpep_pickup_datetime\": \"pickup_datetime\",\n",
    "        \"tpep_dropoff_datetime\": \"dropoff_datetime\",\n",
    "        \"Passenger_Count\": \"Passenger_Count\",\n",
    "        \"Trip_Distance\": \"Trip_Distance\",\n",
    "        \"Start_Lon\": \"Start_Lon\",\n",
    "        \"Start_Lat\": \"Start_Lat\",\n",
    "        \"End_Lon\": \"End_Lon\",\n",
    "        \"End_Lat\": \"End_Lat\",\n",
    "        \"Fare_Amt\": \"Fare_Amt\",\n",
    "        \"Tip_Amt\": \"Tip_Amt\",\n",
    "        \"Total_Amt\": \"Total_Amt\",\n",
    "        \"distance\": \"distance\"\n",
    "\n",
    "\n",
    "    })\n",
    "    df_selected_final = df_selected_final.drop('dropoff_datetime', axis=1)\n",
    "    df_selected_final.rename(columns={\"Trip_Dropoff_DateTime\": \"dropoff_datetime\"})\n",
    "    return df_selected_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "e3d6fd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Taxi_Data = filter_taxi_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "cd6d900e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>Trip_Dropoff_DateTime</th>\n",
       "      <th>Passenger_Count</th>\n",
       "      <th>Trip_Distance</th>\n",
       "      <th>Start_Lon</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>End_Lon</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>Fare_Amt</th>\n",
       "      <th>Tip_Amt</th>\n",
       "      <th>Total_Amt</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-12 21:11:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-73.989845</td>\n",
       "      <td>40.762253</td>\n",
       "      <td>-73.999918</td>\n",
       "      <td>40.748427</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.30</td>\n",
       "      <td>1.090615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-14 01:49:41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>-73.989845</td>\n",
       "      <td>40.762253</td>\n",
       "      <td>-73.990458</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1.512552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-17 19:20:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>-73.985937</td>\n",
       "      <td>40.727620</td>\n",
       "      <td>-74.016079</td>\n",
       "      <td>40.712038</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>15.20</td>\n",
       "      <td>1.913164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-28 08:39:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>-73.990458</td>\n",
       "      <td>40.740337</td>\n",
       "      <td>-74.007486</td>\n",
       "      <td>40.726290</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.08</td>\n",
       "      <td>10.38</td>\n",
       "      <td>1.318463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-30 09:48:52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-73.985937</td>\n",
       "      <td>40.727620</td>\n",
       "      <td>-73.997380</td>\n",
       "      <td>40.728340</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.80</td>\n",
       "      <td>0.602720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183441</th>\n",
       "      <td>2009-12-07 18:20:00</td>\n",
       "      <td>2009-12-07 18:30:47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>-73.973607</td>\n",
       "      <td>40.764044</td>\n",
       "      <td>-73.952651</td>\n",
       "      <td>40.778368</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.60</td>\n",
       "      <td>1.478338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183442</th>\n",
       "      <td>2009-12-16 06:53:14</td>\n",
       "      <td>2009-12-16 07:01:15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.70</td>\n",
       "      <td>-73.978104</td>\n",
       "      <td>40.752521</td>\n",
       "      <td>-73.976706</td>\n",
       "      <td>40.739227</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.920250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183443</th>\n",
       "      <td>2009-12-13 20:43:54</td>\n",
       "      <td>2009-12-13 20:47:29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-73.957094</td>\n",
       "      <td>40.775995</td>\n",
       "      <td>-73.951589</td>\n",
       "      <td>40.773130</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.10</td>\n",
       "      <td>0.349963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183444</th>\n",
       "      <td>2009-12-15 20:34:11</td>\n",
       "      <td>2009-12-15 20:37:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-73.974285</td>\n",
       "      <td>40.753180</td>\n",
       "      <td>-73.972398</td>\n",
       "      <td>40.746405</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.477866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183445</th>\n",
       "      <td>2009-12-29 17:21:00</td>\n",
       "      <td>2009-12-29 17:28:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-73.975162</td>\n",
       "      <td>40.741643</td>\n",
       "      <td>-73.989747</td>\n",
       "      <td>40.741785</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0.765523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>183446 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           pickup_datetime Trip_Dropoff_DateTime  Passenger_Count  \\\n",
       "0      2015-01-12 21:11:01                   NaN              1.0   \n",
       "1      2015-01-14 01:49:41                   NaN              2.0   \n",
       "2      2015-01-17 19:20:20                   NaN              5.0   \n",
       "3      2015-01-28 08:39:20                   NaN              5.0   \n",
       "4      2015-01-30 09:48:52                   NaN              2.0   \n",
       "...                    ...                   ...              ...   \n",
       "183441 2009-12-07 18:20:00   2009-12-07 18:30:47              1.0   \n",
       "183442 2009-12-16 06:53:14   2009-12-16 07:01:15              3.0   \n",
       "183443 2009-12-13 20:43:54   2009-12-13 20:47:29              1.0   \n",
       "183444 2009-12-15 20:34:11   2009-12-15 20:37:20              1.0   \n",
       "183445 2009-12-29 17:21:00   2009-12-29 17:28:00              5.0   \n",
       "\n",
       "        Trip_Distance  Start_Lon  Start_Lat    End_Lon    End_Lat  Fare_Amt  \\\n",
       "0                1.00 -73.989845  40.762253 -73.999918  40.748427       5.0   \n",
       "1                1.48 -73.989845  40.762253 -73.990458  40.740337       7.0   \n",
       "2                2.89 -73.985937  40.727620 -74.016079  40.712038      12.0   \n",
       "3                1.47 -73.990458  40.740337 -74.007486  40.726290       7.5   \n",
       "4                0.50 -73.985937  40.727620 -73.997380  40.728340       5.0   \n",
       "...               ...        ...        ...        ...        ...       ...   \n",
       "183441           1.80 -73.973607  40.764044 -73.952651  40.778368       8.1   \n",
       "183442           1.70 -73.978104  40.752521 -73.976706  40.739227       6.9   \n",
       "183443           0.50 -73.957094  40.775995 -73.951589  40.773130       4.1   \n",
       "183444           0.70 -73.974285  40.753180 -73.972398  40.746405       4.1   \n",
       "183445           1.24 -73.975162  40.741643 -73.989747  40.741785       5.7   \n",
       "\n",
       "        Tip_Amt  Total_Amt  distance  \n",
       "0          0.00       6.30  1.090615  \n",
       "1          0.00       8.30  1.512552  \n",
       "2          2.40      15.20  1.913164  \n",
       "3          2.08      10.38  1.318463  \n",
       "4          0.00       5.80  0.602720  \n",
       "...         ...        ...       ...  \n",
       "183441     0.00       9.60  1.478338  \n",
       "183442     0.00       7.40  0.920250  \n",
       "183443     0.00       5.10  0.349963  \n",
       "183444     1.00       6.10  0.477866  \n",
       "183445     0.00       7.20  0.765523  \n",
       "\n",
       "[183446 rows x 12 columns]"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Taxi_Data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094b4d6d",
   "metadata": {},
   "source": [
    "### Processing Uber Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "7c58e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function first loads the uber data from the csv file. \n",
    "We then filter based on coordinates to make sure the rides are within the coordinates we want.\n",
    "We also remove trips with 0 passangers and no fares. We further remove trips with passangers above 6 as that \n",
    "is uber policy. Lastly we remove trips with no distace between dropoff and pickup. The output is the\n",
    "cleaned dataframe\"\"\"\n",
    "\n",
    "def load_and_clean_uber_data(csv_file: str) -> pd.DataFrame:\n",
    "\n",
    "    # Reading in file into a data frame \n",
    "    uber_data = pd.read_csv(csv_file)\n",
    "\n",
    "    # Filter data based on pickup and dropoff latitude/longitude(40.560445, -74.242330) and (40.908524, -73.717047).\n",
    "\n",
    "    uber_data = uber_data[(uber_data[\"pickup_latitude\"] >= 40.560445) & \n",
    "                      (uber_data[\"pickup_longitude\"] >= -74.242330) & \n",
    "                      (uber_data[\"pickup_latitude\"] <= 40.908524) & \n",
    "                      (uber_data[\"pickup_longitude\"] <= -73.717047) &\n",
    "                      (uber_data[\"dropoff_latitude\"] >= 40.560445) & \n",
    "                      (uber_data[\"dropoff_longitude\"] >= -74.242330) & \n",
    "                      (uber_data[\"dropoff_latitude\"] <= 40.908524) & \n",
    "                      (uber_data[\"dropoff_longitude\"] <= -73.717047)]\n",
    "    \n",
    "    # Checking if there are any null values for pickup_longitude, pickup_latitude, dropoff_longitude, dropoff_latitude\n",
    "    null_drop_lat = uber_data[uber_data['dropoff_latitude'].isnull()]\n",
    "    null_drop_long = uber_data[uber_data['dropoff_longitude'].isnull()]\n",
    "    null_pick_lat= uber_data[uber_data['pickup_latitude'].isnull()]\n",
    "    null_pick_long = uber_data[uber_data['pickup_longitude'].isnull()]\n",
    "\n",
    "    # Return True, if none of the colums have null values \n",
    "\n",
    "   # if null_drop_lat.empty & null_drop_long.empty & null_pick_lat.empty & null_pick_long.empty :\n",
    "        #print(True)\n",
    "    #else:\n",
    "       # print(False)\n",
    "\n",
    "    \n",
    "    # Removing rows where passamger count is 0 \n",
    "    uber_data = uber_data[uber_data['passenger_count']!=0]\n",
    "\n",
    "\n",
    "    # Removing rows with passanger data is abnormally large \n",
    "    uber_data = uber_data[uber_data['passenger_count']<=6]\n",
    "\n",
    "    # Checking datatypes for all columns \n",
    "    #print(uber_data.dtypes)\n",
    "\n",
    "    #Making sure pickup time is a datetime object and normalizing the name \n",
    "    uber_data ['pickup_time'] = pd.to_datetime(uber_data ['pickup_datetime'])\n",
    " \n",
    "    return uber_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "90d2ceba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>key</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24238194</td>\n",
       "      <td>2015-05-07 19:52:06.0000003</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2015-05-07 19:52:06 UTC</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27835199</td>\n",
       "      <td>2009-07-17 20:04:56.0000002</td>\n",
       "      <td>7.7</td>\n",
       "      <td>2009-07-17 20:04:56 UTC</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44984355</td>\n",
       "      <td>2009-08-24 21:45:00.00000061</td>\n",
       "      <td>12.9</td>\n",
       "      <td>2009-08-24 21:45:00 UTC</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25894730</td>\n",
       "      <td>2009-06-26 08:22:21.0000001</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2009-06-26 08:22:21 UTC</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17610152</td>\n",
       "      <td>2014-08-28 17:47:00.000000188</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2014-08-28 17:47:00 UTC</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>42598914</td>\n",
       "      <td>2012-10-28 10:49:00.00000053</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2012-10-28 10:49:00 UTC</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>16382965</td>\n",
       "      <td>2014-03-14 01:09:00.0000008</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2014-03-14 01:09:00 UTC</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>27804658</td>\n",
       "      <td>2009-06-29 00:42:00.00000078</td>\n",
       "      <td>30.9</td>\n",
       "      <td>2009-06-29 00:42:00 UTC</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>20259894</td>\n",
       "      <td>2015-05-20 14:56:25.0000004</td>\n",
       "      <td>14.5</td>\n",
       "      <td>2015-05-20 14:56:25 UTC</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>11951496</td>\n",
       "      <td>2010-05-15 04:08:00.00000076</td>\n",
       "      <td>14.1</td>\n",
       "      <td>2010-05-15 04:08:00 UTC</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194786 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                            key  fare_amount  \\\n",
       "0         24238194    2015-05-07 19:52:06.0000003          7.5   \n",
       "1         27835199    2009-07-17 20:04:56.0000002          7.7   \n",
       "2         44984355   2009-08-24 21:45:00.00000061         12.9   \n",
       "3         25894730    2009-06-26 08:22:21.0000001          5.3   \n",
       "4         17610152  2014-08-28 17:47:00.000000188         16.0   \n",
       "...            ...                            ...          ...   \n",
       "199995    42598914   2012-10-28 10:49:00.00000053          3.0   \n",
       "199996    16382965    2014-03-14 01:09:00.0000008          7.5   \n",
       "199997    27804658   2009-06-29 00:42:00.00000078         30.9   \n",
       "199998    20259894    2015-05-20 14:56:25.0000004         14.5   \n",
       "199999    11951496   2010-05-15 04:08:00.00000076         14.1   \n",
       "\n",
       "                pickup_datetime  pickup_longitude  pickup_latitude  \\\n",
       "0       2015-05-07 19:52:06 UTC        -73.999817        40.738354   \n",
       "1       2009-07-17 20:04:56 UTC        -73.994355        40.728225   \n",
       "2       2009-08-24 21:45:00 UTC        -74.005043        40.740770   \n",
       "3       2009-06-26 08:22:21 UTC        -73.976124        40.790844   \n",
       "4       2014-08-28 17:47:00 UTC        -73.925023        40.744085   \n",
       "...                         ...               ...              ...   \n",
       "199995  2012-10-28 10:49:00 UTC        -73.987042        40.739367   \n",
       "199996  2014-03-14 01:09:00 UTC        -73.984722        40.736837   \n",
       "199997  2009-06-29 00:42:00 UTC        -73.986017        40.756487   \n",
       "199998  2015-05-20 14:56:25 UTC        -73.997124        40.725452   \n",
       "199999  2010-05-15 04:08:00 UTC        -73.984395        40.720077   \n",
       "\n",
       "        dropoff_longitude  dropoff_latitude  passenger_count  \\\n",
       "0              -73.999512         40.723217                1   \n",
       "1              -73.994710         40.750325                1   \n",
       "2              -73.962565         40.772647                1   \n",
       "3              -73.965316         40.803349                3   \n",
       "4              -73.973082         40.761247                5   \n",
       "...                   ...               ...              ...   \n",
       "199995         -73.986525         40.740297                1   \n",
       "199996         -74.006672         40.739620                1   \n",
       "199997         -73.858957         40.692588                2   \n",
       "199998         -73.983215         40.695415                1   \n",
       "199999         -73.985508         40.768793                1   \n",
       "\n",
       "                     pickup_time  \n",
       "0      2015-05-07 19:52:06+00:00  \n",
       "1      2009-07-17 20:04:56+00:00  \n",
       "2      2009-08-24 21:45:00+00:00  \n",
       "3      2009-06-26 08:22:21+00:00  \n",
       "4      2014-08-28 17:47:00+00:00  \n",
       "...                          ...  \n",
       "199995 2012-10-28 10:49:00+00:00  \n",
       "199996 2014-03-14 01:09:00+00:00  \n",
       "199997 2009-06-29 00:42:00+00:00  \n",
       "199998 2015-05-20 14:56:25+00:00  \n",
       "199999 2010-05-15 04:08:00+00:00  \n",
       "\n",
       "[194786 rows x 10 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_clean_uber_data(\"uber_rides_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "f836f118",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" We use the add distance column fcuntion we had defined before to add a new column with the distance \n",
    "of the ride to our uber data. We also drop columns where the distance of the ride is ==0\"\"\"\n",
    "\n",
    "def get_uber_data() -> pd.DataFrame:\n",
    "    uber_dataframe = load_and_clean_uber_data(\"uber_rides_sample.csv\")\n",
    "    add_distance_column(uber_dataframe)\n",
    "    uber_dataframe = uber_dataframe.drop(index=uber_dataframe[uber_dataframe['distance'] == 0].index)\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "9c2bd13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "826a4896",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing unnecessary columns \n",
    "final_uber_data = final_uber_data.drop('Unnamed: 0', axis=1)\n",
    "final_uber_data = final_uber_data.drop('key', axis=1)\n",
    "final_uber_data = final_uber_data.drop('pickup_datetime', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "339997e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>-73.999817</td>\n",
       "      <td>40.738354</td>\n",
       "      <td>-73.999512</td>\n",
       "      <td>40.723217</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-07 19:52:06+00:00</td>\n",
       "      <td>1.044594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.7</td>\n",
       "      <td>-73.994355</td>\n",
       "      <td>40.728225</td>\n",
       "      <td>-73.994710</td>\n",
       "      <td>40.750325</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-07-17 20:04:56+00:00</td>\n",
       "      <td>1.525071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.9</td>\n",
       "      <td>-74.005043</td>\n",
       "      <td>40.740770</td>\n",
       "      <td>-73.962565</td>\n",
       "      <td>40.772647</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-08-24 21:45:00+00:00</td>\n",
       "      <td>3.131464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.3</td>\n",
       "      <td>-73.976124</td>\n",
       "      <td>40.790844</td>\n",
       "      <td>-73.965316</td>\n",
       "      <td>40.803349</td>\n",
       "      <td>3</td>\n",
       "      <td>2009-06-26 08:22:21+00:00</td>\n",
       "      <td>1.032372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>-73.925023</td>\n",
       "      <td>40.744085</td>\n",
       "      <td>-73.973082</td>\n",
       "      <td>40.761247</td>\n",
       "      <td>5</td>\n",
       "      <td>2014-08-28 17:47:00+00:00</td>\n",
       "      <td>2.786061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-73.987042</td>\n",
       "      <td>40.739367</td>\n",
       "      <td>-73.986525</td>\n",
       "      <td>40.740297</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-28 10:49:00+00:00</td>\n",
       "      <td>0.069673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>7.5</td>\n",
       "      <td>-73.984722</td>\n",
       "      <td>40.736837</td>\n",
       "      <td>-74.006672</td>\n",
       "      <td>40.739620</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-03-14 01:09:00+00:00</td>\n",
       "      <td>1.167951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>30.9</td>\n",
       "      <td>-73.986017</td>\n",
       "      <td>40.756487</td>\n",
       "      <td>-73.858957</td>\n",
       "      <td>40.692588</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-06-29 00:42:00+00:00</td>\n",
       "      <td>7.995752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>14.5</td>\n",
       "      <td>-73.997124</td>\n",
       "      <td>40.725452</td>\n",
       "      <td>-73.983215</td>\n",
       "      <td>40.695415</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-05-20 14:56:25+00:00</td>\n",
       "      <td>2.197512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>14.1</td>\n",
       "      <td>-73.984395</td>\n",
       "      <td>40.720077</td>\n",
       "      <td>-73.985508</td>\n",
       "      <td>40.768793</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-15 04:08:00+00:00</td>\n",
       "      <td>3.362040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192829 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        fare_amount  pickup_longitude  pickup_latitude  dropoff_longitude  \\\n",
       "0               7.5        -73.999817        40.738354         -73.999512   \n",
       "1               7.7        -73.994355        40.728225         -73.994710   \n",
       "2              12.9        -74.005043        40.740770         -73.962565   \n",
       "3               5.3        -73.976124        40.790844         -73.965316   \n",
       "4              16.0        -73.925023        40.744085         -73.973082   \n",
       "...             ...               ...              ...                ...   \n",
       "199995          3.0        -73.987042        40.739367         -73.986525   \n",
       "199996          7.5        -73.984722        40.736837         -74.006672   \n",
       "199997         30.9        -73.986017        40.756487         -73.858957   \n",
       "199998         14.5        -73.997124        40.725452         -73.983215   \n",
       "199999         14.1        -73.984395        40.720077         -73.985508   \n",
       "\n",
       "        dropoff_latitude  passenger_count               pickup_time  distance  \n",
       "0              40.723217                1 2015-05-07 19:52:06+00:00  1.044594  \n",
       "1              40.750325                1 2009-07-17 20:04:56+00:00  1.525071  \n",
       "2              40.772647                1 2009-08-24 21:45:00+00:00  3.131464  \n",
       "3              40.803349                3 2009-06-26 08:22:21+00:00  1.032372  \n",
       "4              40.761247                5 2014-08-28 17:47:00+00:00  2.786061  \n",
       "...                  ...              ...                       ...       ...  \n",
       "199995         40.740297                1 2012-10-28 10:49:00+00:00  0.069673  \n",
       "199996         40.739620                1 2014-03-14 01:09:00+00:00  1.167951  \n",
       "199997         40.692588                2 2009-06-29 00:42:00+00:00  7.995752  \n",
       "199998         40.695415                1 2015-05-20 14:56:25+00:00  2.197512  \n",
       "199999         40.768793                1 2010-05-15 04:08:00+00:00  3.362040  \n",
       "\n",
       "[192829 rows x 8 columns]"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_uber_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a15cbb",
   "metadata": {},
   "source": [
    "### Processing Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "0ec5370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function takes all the weather files, iterates through them and merges them \n",
    "into one dataframe. The output is the combined dataframe\"\"\"\n",
    "\n",
    "def get_all_weather_csvs() -> pd.DataFrame:\n",
    "    years = list(range(2009, 2016))\n",
    "\n",
    "    # Initialize an empty list to store the dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    # Iterate over the weather files\n",
    "    for year in years:\n",
    "        filepath = f\"{year}_weather.csv\"\n",
    "        df = pd.read_csv(filepath)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Concatenate all the dataframes into a single dataframe\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "fb7e80e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function first loads the uber data from the csv file. \n",
    "We then filter based on coordinates to make sure the rides are within the coordinates we want.\n",
    "We also remove trips with 0 passangers and no fares. We further remove trips with passangers above 6 as that \n",
    "is uber policy. Lastly we remove trips with no distace between dropoff and pickup. The output is the\n",
    "cleaned dataframe\"\"\"\n",
    "\n",
    "def load_and_clean_weather_data() -> pd.DataFrame:\n",
    "\n",
    "    df = get_all_weather_csvs()\n",
    "\n",
    "    df1 = df[['STATION', 'DATE', 'LATITUDE', 'LONGITUDE', 'NAME','HourlyPrecipitation','HourlyWindGustSpeed', 'HourlyWindSpeed', 'DailyAverageWindSpeed','DailyPrecipitation']]\n",
    "    df2 = df1.dropna(subset=['HourlyPrecipitation', 'HourlyWindGustSpeed'])\n",
    "\n",
    "    #column_types = df2.dtypes\n",
    "\n",
    "    #print(column_types)\n",
    "\n",
    "    # we see that the averages for wind speed and precipitation are null for all values so we can drop the columns \n",
    "\n",
    "    # We also doing need the hourly wind gust speed as we will be using the hourly wind speed, we can drop that column as well\n",
    "\n",
    "    df2 = df2.drop(columns=['DailyAverageWindSpeed','DailyPrecipitation', 'HourlyWindGustSpeed','LATITUDE', 'LONGITUDE'])\n",
    "    df2['DATE'] = pd.to_datetime(df['DATE'])\n",
    "\n",
    "    df2\n",
    "\n",
    "    # Removing all rows where Hourly preicipitation has the value \"T\" as we do not need to measure trace amounts \n",
    "\n",
    "    df3 = df2[df2['HourlyPrecipitation'] != \"T\"]\n",
    "\n",
    "    df4 = df3.drop(columns=[\"STATION\"])\n",
    "\n",
    "    df4 = df4.reset_index()\n",
    "\n",
    "    df4['DATE'] = df4['DATE'].apply(lambda x: x.to_pydatetime())\n",
    "\n",
    "    df4['DATE'] = pd.to_datetime(df4['DATE'])\n",
    "\n",
    "    df4['HourlyPrecipitation'] = df4['HourlyPrecipitation'].str.replace(r'(\\d+)\\s*[sS]$', r'\\1', regex=True)\n",
    "    \n",
    "    # convert column \"A\" from object to float\n",
    "    df4['HourlyPrecipitation'] = df4['HourlyPrecipitation'].astype(float)\n",
    "\n",
    "    Weather_Data = df4.drop('index', axis=1)\n",
    "\n",
    "    return  Weather_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "7a3a9156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-06 20:00:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-01-06 23:38:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-01-07 02:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.09</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-01-07 03:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.06</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-01-07 04:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.07</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>2015-12-29 10:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>2015-12-29 11:33:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>2015-12-29 11:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>2015-12-31 11:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>2015-12-31 20:51:00</td>\n",
       "      <td>NY CITY CENTRAL PARK, NY US</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7103 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    DATE                         NAME  HourlyPrecipitation  \\\n",
       "0    2009-01-06 20:00:00  NY CITY CENTRAL PARK, NY US                 0.01   \n",
       "1    2009-01-06 23:38:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "2    2009-01-07 02:51:00  NY CITY CENTRAL PARK, NY US                 0.09   \n",
       "3    2009-01-07 03:51:00  NY CITY CENTRAL PARK, NY US                 0.06   \n",
       "4    2009-01-07 04:51:00  NY CITY CENTRAL PARK, NY US                 0.07   \n",
       "...                  ...                          ...                  ...   \n",
       "7098 2015-12-29 10:51:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "7099 2015-12-29 11:33:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "7100 2015-12-29 11:51:00  NY CITY CENTRAL PARK, NY US                 0.02   \n",
       "7101 2015-12-31 11:51:00  NY CITY CENTRAL PARK, NY US                 0.00   \n",
       "7102 2015-12-31 20:51:00  NY CITY CENTRAL PARK, NY US                 0.00   \n",
       "\n",
       "      HourlyWindSpeed  \n",
       "0                10.0  \n",
       "1                11.0  \n",
       "2                13.0  \n",
       "3                15.0  \n",
       "4                16.0  \n",
       "...               ...  \n",
       "7098             10.0  \n",
       "7099              8.0  \n",
       "7100              6.0  \n",
       "7101              9.0  \n",
       "7102             10.0  \n",
       "\n",
       "[7103 rows x 4 columns]"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "0687581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Roll up the data to daily\"\"\"\n",
    "def clean_month_weather_data_daily() -> pd.DataFrame:\n",
    "\n",
    "    daily_data = load_and_clean_weather_data()\n",
    "\n",
    "    daily_data_final = daily_data.groupby([daily_data['DATE'].dt.year, daily_data['DATE'].dt.month, daily_data['DATE'].dt.day]).sum()[['HourlyPrecipitation', \"HourlyWindSpeed\" ]]\n",
    "\n",
    "    daily_data_final = daily_data_final.rename_axis(index=['Year', 'Month', 'Day'])\n",
    "    \n",
    "    return daily_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "e3e6f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly() -> pd.DataFrame:\n",
    "\n",
    "    hourly_data = load_and_clean_weather_data()\n",
    "\n",
    "    hourly_data_final = hourly_data.groupby([hourly_data['DATE'].dt.year, hourly_data['DATE'].dt.month, hourly_data['DATE'].dt.day, hourly_data['DATE'].dt.hour]).sum()[['HourlyPrecipitation', \"HourlyWindSpeed\" ]]\n",
    "\n",
    "    hourly_data_final = hourly_data_final.rename_axis(index=['Year', 'Month', 'Day', 'Hour'])\n",
    "    \n",
    "    return hourly_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "f7cd53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "48216557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2009</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>20</th>\n",
       "      <td>0.01</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.02</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">7</th>\n",
       "      <th>2</th>\n",
       "      <td>0.09</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.07</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     HourlyPrecipitation  HourlyWindSpeed\n",
       "Year Month Day Hour                                      \n",
       "2009 1     6   20                   0.01             10.0\n",
       "               23                   0.02             11.0\n",
       "           7   2                    0.09             13.0\n",
       "               3                    0.06             15.0\n",
       "               4                    0.07             16.0"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_weather_data = clean_month_weather_data_hourly()\n",
    "hourly_weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "4cb386ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (9,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (8,9,10,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (7,8,9,10,17,18,42,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (17,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (8,9,17,18,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n",
      "/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1094114271.py:13: DtypeWarning: Columns (10,41,78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filepath)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>HourlyPrecipitation</th>\n",
       "      <th>HourlyWindSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.03</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.13</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.06</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.26</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.69</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>0.02</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>29</td>\n",
       "      <td>0.75</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year  Month  Day  HourlyPrecipitation  HourlyWindSpeed\n",
       "0     2009      1    6                 0.03             21.0\n",
       "1     2009      1    7                 1.13            224.0\n",
       "2     2009      1   10                 0.06             48.0\n",
       "3     2009      1   11                 0.26             67.0\n",
       "4     2009      1   17                 0.69              7.0\n",
       "...    ...    ...  ...                  ...              ...\n",
       "1026  2015     12   26                 0.00             76.0\n",
       "1027  2015     12   27                 0.02             58.0\n",
       "1028  2015     12   28                 0.00             70.0\n",
       "1029  2015     12   29                 0.75            167.0\n",
       "1030  2015     12   31                 0.00             19.0\n",
       "\n",
       "[1031 rows x 5 columns]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_data = clean_month_weather_data_daily()\n",
    "daily_weather_data = daily_weather_data.reset_index()\n",
    "\n",
    "daily_weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd101f11",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "f3529cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "d2bea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if using SQL (as opposed to SQLAlchemy), define the commands \n",
    "# to create your 4 tables/dataframes\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS HOURLY_WEATHER (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        year INTEGER,\n",
    "        month INTEGER,\n",
    "        day INTEGER,\n",
    "        hour INTEGER,\n",
    "        precipitation REAL,\n",
    "        wind REAL\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS DAILY_WEATHER (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        year INTEGER,\n",
    "        month INTEGER,\n",
    "        day INTEGER,\n",
    "        precipitation REAL,\n",
    "        wind REAL\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS TAXI_TRIPS (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        pickup_datetime DATETIME,\n",
    "        Trip_Dropoff_DateTime DATETIME\n",
    "        Passenger_Count REAL\n",
    "        Trip_Distance REAL,\n",
    "        Start_Lon REAL,\n",
    "        Start_Lat REAL,\n",
    "        End_Lon REAL, \n",
    "        End_Lat REAL,\n",
    "        Fare_Amt REAL, \n",
    "        Tip_Amt REAL, \n",
    "        Total_Amt REAL,\n",
    "        distance REAL,\n",
    "\n",
    "    );\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS UBER_TRIPS (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        fare_amount REAL,\n",
    "        pickup_longitude REAL,\n",
    "        pickup_latitude REAL,\n",
    "        dropoff_longitude REAL,\n",
    "        dropoff_latitude REAL,\n",
    "        passenger_count INTEGER,\n",
    "        pickup_time DATETIME,\n",
    "        distance REAL,\n",
    "    );\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "5f41e54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "02eccdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c122964f",
   "metadata": {},
   "source": [
    "### Add Data to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "0e68a363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table():\n",
    "\n",
    "    hourly_weather_data.to_sql(name='HOURLY_WEATHER', con=engine, if_exists='replace', index=False)\n",
    "    daily_weather_data.to_sql(name='DAILY_WEATHER', con=engine, if_exists='replace', index=False)\n",
    "    final_uber_data.to_sql(name='UBER_TRIPS', con=engine, if_exists='replace', index=False)\n",
    "    Taxi_Data.to_sql(name='TAXI_TRIPS', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "write_dataframes_to_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "8e495251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2015-01-12 21:11:01.000000', None, 1.0, 1.0, -73.98984489812494, 40.76225259858687, -73.99991779023728, 40.7484273300986, 5.0, 0.0, 6.3, 1.0906149158476206)\n",
      "('2015-01-14 01:49:41.000000', None, 2.0, 1.48, -73.98984489812494, 40.76225259858687, -73.9904579133977, 40.74033737258096, 7.0, 0.0, 8.3, 1.5125521768123307)\n",
      "('2015-01-17 19:20:20.000000', None, 5.0, 2.89, -73.98593745737395, 40.727620122038296, -74.01607927269924, 40.712037924667264, 12.0, 2.4, 15.2, 1.9131644830367174)\n",
      "('2015-01-28 08:39:20.000000', None, 5.0, 1.47, -73.9904579133977, 40.74033737258096, -74.0074858070925, 40.72629040399525, 7.5, 2.08, 10.38, 1.3184625098943075)\n",
      "('2015-01-30 09:48:52.000000', None, 2.0, 0.5, -73.98593745737395, 40.727620122038296, -73.9973801630823, 40.72834036831643, 5.0, 0.0, 5.8, 0.6027204295949005)\n",
      "('2015-01-21 09:48:39.000000', None, 1.0, 1.1, -73.99991779023728, 40.7484273300986, -73.9904579133977, 40.74033737258096, 7.5, 2.0, 10.3, 0.7470553727411682)\n",
      "('2015-01-28 22:02:40.000000', None, 1.0, 9.45, -73.98593745737395, 40.727620122038296, -73.91969433569462, 40.761492617043125, 28.0, 5.86, 35.16, 4.189127011299069)\n",
      "('2015-01-21 14:54:30.000000', None, 5.0, 1.38, -74.01607927269924, 40.712037924667264, -74.00153759512791, 40.723888072060404, 7.5, 1.5, 9.8, 1.1186963831966343)\n",
      "('2015-01-12 11:46:49.000000', None, 1.0, 0.9, -73.95963501136171, 40.76694805479654, -73.95701192571859, 40.78043629001211, 8.0, 1.75, 10.55, 0.9408450617178153)\n",
      "('2015-01-17 17:11:03.000000', None, 4.0, 1.04, -73.98419655675737, 40.759817566309465, -73.97235615813489, 40.756687537617346, 6.5, 0.0, 7.3, 0.6577345592939466)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "query = \"SELECT * FROM TAXI_TRIPS LIMIT 10;\"\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6e33e",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6a849e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to write the queries to file\n",
    "def write_query_to_file(query, outfile):\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee70a777",
   "metadata": {},
   "source": [
    "### Query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "db871d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('19', 11319)\n",
      "('18', 10938)\n",
      "('20', 10792)\n",
      "('21', 10693)\n",
      "('22', 10330)\n",
      "('23', 9228)\n",
      "('14', 9183)\n",
      "('17', 9134)\n",
      "('12', 8974)\n",
      "('13', 8891)\n",
      "('15', 8866)\n",
      "('09', 8621)\n",
      "('11', 8466)\n",
      "('08', 8315)\n",
      "('10', 8314)\n",
      "('16', 7518)\n",
      "('00', 7417)\n",
      "('07', 6570)\n",
      "('01', 5388)\n",
      "('06', 3849)\n",
      "('02', 3840)\n",
      "('03', 2826)\n",
      "('04', 2161)\n",
      "('05', 1813)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "\n",
    "with open('1_hour_day.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3725eb44",
   "metadata": {},
   "source": [
    "### Query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "41fbf5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Sunday', 25503)\n",
      "('Monday', 24280)\n",
      "('Tuesday', 27152)\n",
      "('Wednesday', 27971)\n",
      "('Thursday', 28960)\n",
      "('Friday', 29749)\n",
      "('Saturday', 29214)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "\n",
    "with open('2_day_week.sql', 'r') as file:\n",
    "    \n",
    "    query = file.read()\n",
    "\n",
    "result = engine.execute(query)\n",
    "\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d53f383c",
   "metadata": {},
   "source": [
    "### Query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "f3b9a12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16.7641931513008,)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "\n",
    "with open('3_95_percentile.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59638822",
   "metadata": {},
   "source": [
    "### Query 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "417b0fa6",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such column: pickup_datetime\n[SQL: SELECT pickup_date, COUNT(*) AS frequency, AVG(distance) AS avg_distance\nFROM (\n  SELECT date(pickup_datetime) AS pickup_date, distance\n  FROM UBER_TRIPS\n  WHERE pickup_datetime BETWEEN '2009-01-01' AND '2009-12-31'\n  UNION ALL\n  SELECT date(pickup_datetime) AS pickup_date, distance\n  FROM TAXI_TRIPS\n  WHERE pickup_datetime BETWEEN '2009-01-01' AND '2009-12-31'\n)\nGROUP BY pickup_date\nORDER BY frequency DESC\nLIMIT 10;]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1818\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1820\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such column: pickup_datetime",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/1277444106.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py\u001b[0m in \u001b[0;36mwarned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0m_warn_with_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   3174\u001b[0m         \"\"\"\n\u001b[1;32m   3175\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3178\u001b[0m     @util.deprecated_20(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1289\u001b[0m             )\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m             return self._exec_driver_sql(\n\u001b[0m\u001b[1;32m   1292\u001b[0m                 \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m                 \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_exec_driver_sql\u001b[0;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m         ret = self._execute_context(\n\u001b[0m\u001b[1;32m   1596\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_statement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m             self._handle_dbapi_exception(\n\u001b[0m\u001b[1;32m   1863\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2041\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m                 util.raise_(\n\u001b[0m\u001b[1;32m   2044\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1820\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m                     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such column: pickup_datetime\n[SQL: SELECT pickup_date, COUNT(*) AS frequency, AVG(distance) AS avg_distance\nFROM (\n  SELECT date(pickup_datetime) AS pickup_date, distance\n  FROM UBER_TRIPS\n  WHERE pickup_datetime BETWEEN '2009-01-01' AND '2009-12-31'\n  UNION ALL\n  SELECT date(pickup_datetime) AS pickup_date, distance\n  FROM TAXI_TRIPS\n  WHERE pickup_datetime BETWEEN '2009-01-01' AND '2009-12-31'\n)\nGROUP BY pickup_date\nORDER BY frequency DESC\nLIMIT 10;]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "\n",
    "with open('4_top_10_days.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12a1fc3e",
   "metadata": {},
   "source": [
    "### Query 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "4c6c70c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such column: pickup_datetime\n[SQL: SELECT t.pickup_date, COUNT(*) AS frequency, AVG(w.wind) AS avg_wind\nFROM (\n  SELECT date(pickup_datetime) AS pickup_date\n  FROM UBER_TRIPS\n  WHERE pickup_datetime BETWEEN '2014-01-01' AND '2014-12-31'\n  UNION ALL\n  SELECT date(pickup_datetime) AS pickup_date\n  FROM TAXI_TRIPS\n  WHERE pickup_datetime BETWEEN '2014-01-01' AND '2014-12-31'\n) t\nJOIN DAILY_WEATHER w\nON t.pickup_date = date(w.year || '-' || w.month || '-' || w.day)\nGROUP BY t.pickup_date\nORDER BY avg_wind DESC\nLIMIT 10;]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1818\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1820\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such column: pickup_datetime",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4y/mgwhf9fd22746wblcfjds5gc0000gn/T/ipykernel_74492/3252899061.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/deprecations.py\u001b[0m in \u001b[0;36mwarned\u001b[0;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mskip_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0m_warn_with_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   3174\u001b[0m         \"\"\"\n\u001b[1;32m   3175\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3178\u001b[0m     @util.deprecated_20(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1289\u001b[0m             )\n\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m             return self._exec_driver_sql(\n\u001b[0m\u001b[1;32m   1292\u001b[0m                 \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m                 \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_exec_driver_sql\u001b[0;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[1;32m   1593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m         ret = self._execute_context(\n\u001b[0m\u001b[1;32m   1596\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_statement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m             self._handle_dbapi_exception(\n\u001b[0m\u001b[1;32m   1863\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2041\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m                 util.raise_(\n\u001b[0m\u001b[1;32m   2044\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1817\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1818\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1819\u001b[0;31m                     self.dialect.do_execute(\n\u001b[0m\u001b[1;32m   1820\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m                     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such column: pickup_datetime\n[SQL: SELECT t.pickup_date, COUNT(*) AS frequency, AVG(w.wind) AS avg_wind\nFROM (\n  SELECT date(pickup_datetime) AS pickup_date\n  FROM UBER_TRIPS\n  WHERE pickup_datetime BETWEEN '2014-01-01' AND '2014-12-31'\n  UNION ALL\n  SELECT date(pickup_datetime) AS pickup_date\n  FROM TAXI_TRIPS\n  WHERE pickup_datetime BETWEEN '2014-01-01' AND '2014-12-31'\n) t\nJOIN DAILY_WEATHER w\nON t.pickup_date = date(w.year || '-' || w.month || '-' || w.day)\nGROUP BY t.pickup_date\nORDER BY avg_wind DESC\nLIMIT 10;]\n(Background on this error at: https://sqlalche.me/e/14/e3q8)"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "\n",
    "with open('5_10_windiest_days.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f5b5a047",
   "metadata": {},
   "source": [
    "### Query 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6eea1fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# establish a connection to the SQL database\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# execute a SELECT query on the HOURLY_WEATHER table\n",
    "\n",
    "with open('6_hurricane.sql', 'r') as file:\n",
    "    query = file.read()\n",
    "\n",
    "result = engine.execute(query)\n",
    "\n",
    "for row in result:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5275f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, QUERY_1_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13ced42",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9eef42",
   "metadata": {},
   "source": [
    "### Visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frequency_hour(dataframe: pd.DataFrame):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    hour = [1, 2, 3, 4, 5]\n",
    "    values = [1, 5, 3, 2, 5]\n",
    "\n",
    "    axes.bar(hour, values)\n",
    "\n",
    "    axes.set_ylabel('Popularity')\n",
    "    axes.set_xlabel('Hour')\n",
    "    axes.set_title(\"Frequency per Hour\")\n",
    "    axes.set_xlim(-1, 11)\n",
    "    axes.set_ylim(-1.5, 1.5)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847ced2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_frequency_hour():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c63e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_frequency_hour()\n",
    "plot_frequency_hour(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c350a277",
   "metadata": {},
   "source": [
    "### Visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "c02eeb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_avg_distance_month(dataframe: pd.DataFrame):\n",
    "    figure, axes = plt.subplots(figsize=(30, 20))\n",
    "    \n",
    "    month = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "    distance = [1, 5, 3, 2, 5, 7, 8, 1, 9, 23, 6, 7]\n",
    "\n",
    "    x = np.linspace(0, 12, 12) \n",
    "\n",
    "    a, b = np.polyfit(x, distance, deg=1)\n",
    "    y_est = a * x + b\n",
    "    y_err = x.std() * np.sqrt(1/len(x) +\n",
    "                            (x - x.mean())**2 / np.sum((x - x.mean())**2))\n",
    "\n",
    "    axes.plot(x, y_est, '-')\n",
    "\n",
    "    axes.plot(month, distance, 'o', color='tab:brown')\n",
    "    axes.fill_between(x, y_est - y_err, y_est + y_err, alpha=0.2)\n",
    "    axes.set_ylabel('Average Distance')\n",
    "    axes.set_xlabel('Month')\n",
    "    axes.set_title(\"Average Distance per Month\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a82b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_avg_distance_month():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3134bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_avg_distance_month()\n",
    "plot_avg_distance_month(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "275a1af2",
   "metadata": {},
   "source": [
    "### Visualization 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e60fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dropoffs_ny_area(dataframe: pd.DataFrame):\n",
    "\n",
    "    days = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "\n",
    "    lga = [4, 5, 1, 8, 3, 9, 2]\n",
    "    jfk = [9, 2, 8, 4, 5, 8, 1]\n",
    "    ewr = [9, 7, 3, 7, 2, 9, 4]\n",
    "\n",
    "    x_axis = np.arange(len(days))\n",
    "  \n",
    "    plt.bar(x_axis - 0.2, lga, 0.4, label = 'LGA')\n",
    "    plt.bar(x_axis + 0.2, jfk, 0.4, label = 'JFK')\n",
    "    plt.bar(x_axis + 0.4, ewr, 0.4, label = 'EWR')\n",
    "\n",
    "    plt.xlabel(\"Days in Week\")\n",
    "    plt.ylabel(\"Drop Offs\")\n",
    "    plt.title(\"Drop-Offs per Airport\")\n",
    "\n",
    "    plt.xticks(x_axis, days)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e9357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dropoffs_ny_area():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60d732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_dropoffs_ny_area()\n",
    "plot_dropoffs_ny_area(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e085f33",
   "metadata": {},
   "source": [
    "### Visualization 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a624df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trips_area(dataframe: pd.DataFrame):    \n",
    "    map_obj = folium.Map(location = [40.730610, -73.935242], zoom_start = 10, min_zoom = 10, tiles='CartoDB positron')\n",
    "\n",
    "    lats_longs = [\n",
    "                    [40.7554, -73.9862],\n",
    "                    [40.7794, -73.9654],\n",
    "                    [40.7223, -73.9982],\n",
    "                    [40.7455, -74.0071],\n",
    "                ]\n",
    "\n",
    "    HeatMap(lats_longs).add_to(map_obj)\n",
    "    return map_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c2c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_trips_area():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30d6254",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_trips_area()\n",
    "plot_trips_area(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9029b60",
   "metadata": {},
   "source": [
    "### Visualization 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "acdcd1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tips_distance(dataframe: pd.DataFrame):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    tips = [2, 6, 3, 7, 8, 1, 9, 22, 9, 6, 22, 1]\n",
    "    distance = [1, 5, 3, 2, 5, 7, 8, 1, 9, 23, 6, 7]\n",
    "\n",
    "    axes.scatter(distance, tips, marker='o', alpha=0.5)\n",
    "    axes.set_title(\"Yellow Tips - Tips vs. Distance\")\n",
    "    axes.set_ylabel('Popularity')\n",
    "    axes.set_xlabel('Distance')\n",
    "    axes.set_xlim(-1, 11)\n",
    "    axes.set_ylim(-1, 10)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tips_distance():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad3a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_tips_distance()\n",
    "plot_tips_distance(some_dataframe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "410cfcdd",
   "metadata": {},
   "source": [
    "### Visualization 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd37fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "17fa4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tips_precipitation(dataframe: pd.DataFrame):\n",
    "    figure, axes = plt.subplots(figsize=(20, 10))\n",
    "    \n",
    "    tips = [2, 6, 3, 7, 8, 1, 9, 22, 9, 6, 22, 1]\n",
    "    precipication = [1, 5, 3, 2, 5, 7, 8, 1, 9, 23, 6, 7]\n",
    "\n",
    "    ## Animation\n",
    "\n",
    "    frames = 10\n",
    "    points = len(tips)\n",
    "    np.random.seed(42)\n",
    "\n",
    "    sizes = itertools.cycle([10, 50, 150])\n",
    "    colors = np.random.rand(frames, points)\n",
    "    colormaps = itertools.cycle(['Purples', 'Blues', 'Greens', 'Oranges', 'Reds'])\n",
    "    markers = itertools.cycle(['o', 'v', '^', 's', 'p'])\n",
    "\n",
    "    def update(i):\n",
    "        axes.clear()\n",
    "\n",
    "        axes.scatter(precipication, tips,\n",
    "                s=next(sizes),\n",
    "                c=colors[i, :],\n",
    "                cmap=next(colormaps),\n",
    "                marker=next(markers),\n",
    "                alpha=0.5)\n",
    "\n",
    "        axes.set_title(\"Yellow Taxi - Tips vs. Precipitation\")\n",
    "        axes.set_ylabel('Precipitation')\n",
    "        axes.set_xlabel('Tips')\n",
    "        axes.set_xlim(-1, 11)\n",
    "        axes.set_ylim(-1, 10)\n",
    "\n",
    "    anim = animation.FuncAnimation(figure, update, frames=frames, interval=500)\n",
    "    anim\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c3689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_tips_precipitation():\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b2d0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_tips_precipitation()\n",
    "plot_tips_precipitation(some_dataframe)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2d659ea492a6423f437f8c825d2ef59ba06a7f23250fb4bfa35b0a006bd446c8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
